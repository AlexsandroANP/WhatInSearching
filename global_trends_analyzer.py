import streamlit as st
import os
import json
from datetime import datetime, timedelta
from collections import defaultdict
import tiktoken  # ç”¨äºä¼°ç®— token æ•°é‡
import openai
from openai import OpenAI
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# å¯¼å…¥é…ç½®æ¨¡å—
from config import get_config
config = get_config()

# --- è®¾ç½®å·¥ä½œç›®å½•ä¸ºè„šæœ¬æ‰€åœ¨ç›®å½• ---
# è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
# åˆ‡æ¢åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•
os.chdir(script_dir)
# st.write(f"å·¥ä½œç›®å½•å·²è®¾ç½®ä¸º: {os.getcwd()}") # å¯é€‰ï¼šæ‰“å°å½“å‰å·¥ä½œç›®å½•ä»¥ç¡®è®¤


# --- é…ç½® ---
# 1. æŒ‡å®šåŒ…å« JSON æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„è·¯å¾„)
FOLDER_PATH = 'JSONs'  # <--- ä¿®æ”¹æ­¤è·¯å¾„
JSON_FILENAME_PATTERN = 'trends_{}.json' # JSON æ–‡ä»¶åçš„æ¨¡å¼ï¼Œ{} ä¼šè¢«æ—¥æœŸæ›¿æ¢

# å¯¼å…¥é…ç½®å’Œå‡­è¯æ¨¡å—
# ä»configä¸­è·å–æç¤ºè¯é…ç½®
AI_DEFAULT_USER_PROMPT = config.PROMPTS["AI_DEFAULT_USER_PROMPT"]
AI_DEFAULT_TABLE_CONTENT_PLACEHOLDER = config.PROMPTS["AI_DEFAULT_TABLE_CONTENT_PLACEHOLDER"]
AI_DEFAULT_SYSTEM_PROMPT = config.PROMPTS["AI_DEFAULT_SYSTEM_PROMPT"]
from credentials import (
    MODEL_API_KEY,
    MODEL_API_ENDPOINT,
    MODEL_NAME
)

# --- AI é…ç½® ---
# ä½ å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹é»˜è®¤å€¼ï¼Œä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
DEFAULT_ENDPOINT = MODEL_API_ENDPOINT  # ä»å‡­è¯æ¨¡å—å¯¼å…¥
DEFAULT_API_KEY = MODEL_API_KEY  # ä»å‡­è¯æ¨¡å—å¯¼å…¥
DEFAULT_MODEL = MODEL_NAME  # ä»å‡­è¯æ¨¡å—å¯¼å…¥
DEFAULT_MAX_TOKENS = 128*1024  # 64K tokens
DEFAULT_USER_PROMPT = AI_DEFAULT_USER_PROMPT  # ä»æç¤ºè¯æ¨¡å—å¯¼å…¥
DEFAULT_TABLE_CONTENT_PLACEHOLDER = AI_DEFAULT_TABLE_CONTENT_PLACEHOLDER  # ä»æç¤ºè¯æ¨¡å—å¯¼å…¥
DEFAULT_SYSTEM_PROMPT = AI_DEFAULT_SYSTEM_PROMPT  # ä»æç¤ºè¯æ¨¡å—å¯¼å…¥


# --- å‡½æ•°å®šä¹‰ ---
def parse_pub_date(pub_date_str):
    """è§£æ ISO 8601 æ ¼å¼çš„ pubDate å­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡"""
    # ç¤ºä¾‹æ ¼å¼: "2025-10-21T17:20:00-07:00", "2025-12-30"
    try:
        # Python çš„ fromisoformat åœ¨ 3.11+ ä¸­æ”¯æŒå¸¦æ—¶åŒºçš„æ ¼å¼ï¼Œå¯¹äºæ—§ç‰ˆæœ¬ï¼Œéœ€è¦æ‰‹åŠ¨å¤„ç†
        # ç§»é™¤æ—¶åŒºåç§»éƒ¨åˆ†å¹¶æ‰‹åŠ¨è§£æ
        # æ ¼å¼ä¸º YYYY-MM-DDTHH:MM:SS+HH:MM æˆ– -HH:MM
        # è¿™é‡Œç®€å•åœ°ç§»é™¤æ—¶åŒºéƒ¨åˆ†ï¼Œåªå–æ—¥æœŸæ—¶é—´
        # æ›´ç²¾ç¡®çš„å¤„ç†å¯ä»¥ä½¿ç”¨ dateutil åº“
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œè¿™é‡Œæ‰‹åŠ¨åˆ†å‰²
        if pub_date_str:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´éƒ¨åˆ†
            if 'T' in pub_date_str:
                # åˆ†å‰²æ—¥æœŸæ—¶é—´å’Œæ—¶åŒº
                dt_part = pub_date_str.split('T')[0]
                time_part = pub_date_str.split('T')[1].split('-')[0].split('+')[0] # ç§»é™¤æ—¶åŒº
                full_dt_str = f"{dt_part}T{time_part}"
                # ç›´æ¥è§£æå®Œæ•´çš„æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²ï¼Œä¸è¿›è¡Œé¢å¤–çš„åˆ†å‰²
                dt = datetime.fromisoformat(full_dt_str.replace('Z', '+00:00'))
            else:
                # ç®€å•æ—¥æœŸæ ¼å¼ï¼Œå¦‚ "2025-12-30"
                dt = datetime.strptime(pub_date_str, '%Y-%m-%d')
            return dt.date()
    except ValueError:
        try:
            # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
            dt = datetime.strptime(pub_date_str.split('T')[0], '%Y-%m-%d')
            return dt.date()
        except ValueError:
            st.warning(f"æ— æ³•è§£ææ—¥æœŸå­—ç¬¦ä¸²: {pub_date_str}")
            return None
    return None

def is_date_in_range(pub_date_str, start_date, end_date):
    """æ£€æŸ¥ pubDate æ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…"""
    parsed_date = parse_pub_date(pub_date_str)
    if parsed_date:
        return start_date <= parsed_date <= end_date
    return False

def load_and_process_file_for_date(target_date, results_list):
    """åŠ è½½å¹¶å¤„ç†æŒ‡å®šæ—¥æœŸçš„ JSON æ–‡ä»¶ï¼Œå°†æ¯ä¸ªæ–°é—»é¡¹ä½œä¸ºä¸€è¡Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­"""
    filename = JSON_FILENAME_PATTERN.format(target_date.strftime('%Y-%m-%d'))
    
    # æœç´¢æ‰€æœ‰å›½å®¶å­æ–‡ä»¶å¤¹ä¸­çš„JSONæ–‡ä»¶
    search_paths = [FOLDER_PATH]
    
    # æ·»åŠ æ‰€æœ‰å›½å®¶å­æ–‡ä»¶å¤¹
    try:
        for item in os.listdir(FOLDER_PATH):
            item_path = os.path.join(FOLDER_PATH, item)
            if os.path.isdir(item_path):
                search_paths.append(item_path)
    except Exception as e:
        st.warning(f"æ— æ³•è¯»å–æ–‡ä»¶å¤¹ç»“æ„: {e}")
    
    # å¤„ç†æ¯ä¸ªå¯èƒ½çš„æ–‡ä»¶è·¯å¾„
    for search_path in search_paths:
        # æ£€æŸ¥æ‰€æœ‰åŒ¹é…æ—¥æœŸå‰ç¼€çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬å¸¦å›½å®¶åç¼€çš„
        base_name, ext = os.path.splitext(filename)
        matching_files = []
        
        try:
            # è·å–è¯¥è·¯å¾„ä¸‹æ‰€æœ‰ä»¥base_nameå¼€å¤´çš„æ–‡ä»¶
            all_files = os.listdir(search_path)
            matching_files = [f for f in all_files if f.startswith(base_name)]
        except Exception as e:
            continue
        
        for matching_file in matching_files:
                file_path = os.path.join(search_path, matching_file)
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                except json.JSONDecodeError as e:
                    st.error(f"è§£ç  JSON æ–‡ä»¶é”™è¯¯ {file_path}: {e}")
                    continue
                except FileNotFoundError:
                    # è¿™ä¸ªé”™è¯¯ç†è®ºä¸Šä¸ä¼šè§¦å‘ï¼Œå› ä¸ºä¸Šé¢å·²ç»æ£€æŸ¥äº†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    st.error(f"æ–‡ä»¶æœªæ‰¾åˆ° (æ­¤é”™è¯¯ä¸åº”å‡ºç°): {file_path}")
                    continue
                except Exception as e:
                    st.error(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ {file_path}: {e}")
                    continue

                if not isinstance(data, list):
                    st.warning(f"è­¦å‘Š: {file_path} ä¸­çš„æ•°æ®ä¸æ˜¯åˆ—è¡¨ã€‚è·³è¿‡ã€‚")
                    continue

                # ä»æ–‡ä»¶å¤¹è·¯å¾„æå–å›½å®¶ä¿¡æ¯
                # ä¾‹å¦‚ï¼šJSONs/India/trends_2025-10-14.json â†’ "India"
                folder_country = None
                # æ£€æŸ¥search_pathæ˜¯å¦æ˜¯FOLDER_PATHçš„å­ç›®å½•
                if search_path != FOLDER_PATH:
                    # è·å–search_pathç›¸å¯¹äºFOLDER_PATHçš„è·¯å¾„
                    relative_path = os.path.relpath(search_path, FOLDER_PATH)
                    # è·å–ç›¸å¯¹è·¯å¾„çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œå³å›½å®¶åç§°
                    folder_country = relative_path.split(os.sep)[0]
                    # éªŒè¯è¿™ä¸ªå›½å®¶åç§°æ˜¯å¦çœŸçš„å­˜åœ¨
                    if not os.path.isdir(os.path.join(FOLDER_PATH, folder_country)):
                        folder_country = None

                for item in data:
                    # 1. ç­›é€‰ traffic_num (è¿™é‡Œå‡è®¾æ˜¯ traffic_numï¼ŒåŸä»£ç æ˜¯ traffic)
                    # è°ƒæ•´é˜ˆå€¼ä¸º0ï¼Œæ˜¾ç¤ºæ‰€æœ‰æµé‡æ•°æ®
                    if item.get('traffic_num', 0) < 0: # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´é˜ˆå€¼
                        continue

                    # 2. ç­›é€‰ pub_date æ˜¯å¦ä¸ºå½“å¤© (å› ä¸ºæ–‡ä»¶åå·²ç»é™å®šäº†æ—¥æœŸèŒƒå›´)
                    # æˆ‘ä»¬ä»ç„¶å¯ä»¥æ£€æŸ¥ pub_dateï¼Œä»¥ç¡®ä¿å®ƒä¸æ–‡ä»¶åä»£è¡¨çš„æ—¥æœŸä¸€è‡´
                    pub_date_str = item.get('pub_date')
                    if not pub_date_str:
                        continue # æ²¡æœ‰æ—¥æœŸçš„æ¡ç›®è·³è¿‡

                    # è§£æ pub_dateï¼Œç¡®è®¤å®ƒç¡®å®æ˜¯ç›®æ ‡æ—¥æœŸ
                    item_date = parse_pub_date(pub_date_str)
                    if item_date != target_date:
                        continue # pubDate ä¸æ–‡ä»¶æ—¥æœŸä¸åŒ¹é…ï¼Œè·³è¿‡

                    # 3. æå–æ‰€éœ€ä¿¡æ¯
                    search_term = item.get('title', 'N/A')
                    traffic_num = item.get('traffic_num', 0)
                    pub_date = item_date # ä½¿ç”¨è§£æåçš„æ—¥æœŸ
                    regions = item.get('regions', [])
                    # å¦‚æœJSONä¸­æ²¡æœ‰å›½å®¶ä¿¡æ¯ï¼Œåˆ™ä½¿ç”¨æ–‡ä»¶å¤¹åç§°ä½œä¸ºå›½å®¶
                    country = item.get('country', folder_country)
                    news_list = item.get('news', [])

                    if not news_list:
                         continue # å¦‚æœæ²¡æœ‰ news é¡¹ï¼Œåˆ™è·³è¿‡

                    # éå† news åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ª news_item åˆ›å»ºä¸€è¡Œè®°å½•
                    for news_item in news_list:
                        news_title = news_item.get('title', 'N/A')
                        news_source = news_item.get('source', 'N/A')

                        # æ·»åŠ è¿™ä¸€è¡Œåˆ°ç»“æœåˆ—è¡¨
                        results_list.append({
                            "Search Term": search_term,
                            "News Title": news_title,
                            "News Source": news_source,
                            "Traffic Num": traffic_num,
                            "Pub Date": pub_date,
                            "Regions": regions, # å¯ä»¥ä¿ç•™æ•´ä¸ªåˆ—è¡¨
                            "Country": country # æ·»åŠ å›½å®¶ä¿¡æ¯
                        })

def load_data_by_date_range(start_date, end_date):
    """æ ¹æ®æ—¥æœŸèŒƒå›´åŠ è½½æ•°æ®"""
    all_extracted_data_list = []
    current_date = start_date
    while current_date <= end_date:
        # print(f"Attempting to load file for date: {current_date.strftime('%Y-%m-%d')}") # å¯é€‰ï¼šæ˜¾ç¤ºåŠ è½½è¿›åº¦
        load_and_process_file_for_date(current_date, all_extracted_data_list)
        current_date += timedelta(days=1)

    # æŒ‰å‘å¸ƒæ—¥æœŸï¼ˆé™åºï¼‰å’Œæµé‡æ•°ï¼ˆé™åºï¼‰æ’åº
    all_extracted_data_list.sort(key=lambda x: (x["Pub Date"], x["Traffic Num"]), reverse=True)
    return all_extracted_data_list

def estimate_tokens(text, model_name="gpt-4o"):
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
    """
    try:
        encoding = tiktoken.encoding_for_model(model_name)
    except KeyError:
        encoding = tiktoken.get_encoding("cl100k_base") # fallback
    num_tokens = len(encoding.encode(text))
    return num_tokens

def generate_simple_markdown_table(df_filtered, max_rows=100000):
    """
    ç”Ÿæˆç®€åŒ–ç‰ˆçš„ markdown è¡¨æ ¼
    """
    if df_filtered.empty:
        return "No data to display."

    # é™åˆ¶è¡Œæ•°ä»¥å‡å°‘ token
    df_to_use = df_filtered.head(max_rows)

    # é‡å‘½ååˆ—ä»¥ç¬¦åˆè¦æ±‚
    df_simple = df_to_use.rename(columns={
        "æ ‡é¢˜": "news_title",
        "ä¿¡æº": "source",
        "æœç´¢è¯": "title",
        "æµé‡": "traffic_num",
        "å‘å¸ƒæ—¥æœŸ": "pub_date",
        "åœ°åŒº": "regions",
        "å›½å®¶": "country"
    })

    # è½¬æ¢æ—¥æœŸæ ¼å¼å’Œæµé‡æ ¼å¼
    df_simple["pub_date"] = df_simple["pub_date"].astype(str)
    df_simple["traffic_num"] = df_simple["traffic_num"].astype(int)

    # ç”Ÿæˆ markdown è¡¨æ ¼
    lines = []
    lines.append('')
    lines.append("news_title | source | title | traffic_num | pub_date | regions | country")
    lines.append("---|---|---|---|---|---|---")

    for _, row in df_simple.iterrows():
        line = f"{row['news_title']} | {row['source']} | {row['title']} | {row['traffic_num']} | {row['pub_date']} | {row['regions']} | {row['country']}"
        lines.append(line)

    return "\n".join(lines)


# --- Streamlit åº”ç”¨ ---
st.set_page_config(page_title="Global Trending Now çœ‹æ¿", layout="wide")

# é¡µé¢æ ‡é¢˜å’Œç®€ä»‹
st.title("ğŸ” Global Trending Now ")
st.markdown("### å…¨çƒçƒ­ç‚¹æœç´¢è¶‹åŠ¿åˆ†æå¹³å°")
st.markdown("å®æ—¶è¿½è¸ªå…¨çƒå„å›½çƒ­ç‚¹æœç´¢è¶‹åŠ¿ï¼Œæä¾›æ•°æ®å¯è§†åŒ–å’ŒAIåˆ†æåŠŸèƒ½")

# åˆå§‹åŒ– session state æ¥å­˜å‚¨æ•°æ®
if 'data' not in st.session_state:
    st.session_state['data'] = []
if 'selected_date_range' not in st.session_state:
    st.session_state['selected_date_range'] = '7d' # é»˜è®¤ä¸ºè¿‘7å¤©
if 'df' not in st.session_state:
    st.session_state['df'] = None
if 'df_filtered' not in st.session_state:
    st.session_state['df_filtered'] = None
if 'ai_active' not in st.session_state:
    st.session_state['ai_active'] = False
if 'ai_messages' not in st.session_state:
    st.session_state['ai_messages'] = []
if 'token_count' not in st.session_state:
    st.session_state['token_count'] = 0
if 'ai_client' not in st.session_state:
    st.session_state['ai_client'] = None

# æ—¥æœŸèŒƒå›´é€‰æ‹©åŒºåŸŸ - æ›´çªå‡ºçš„ä½ç½®
st.markdown("## ğŸ“… é€‰æ‹©æ•°æ®æ—¥æœŸèŒƒå›´")
date_container = st.container(border=True)
with date_container:
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("è¿‘ 3 å¤©", use_container_width=True, type="primary" if st.session_state.selected_date_range == '3d' else "secondary"):
            start_date = (datetime.now().date() - timedelta(days=3))
            end_date = datetime.now().date()
            st.session_state['data'] = load_data_by_date_range(start_date, end_date)
            st.session_state['selected_date_range'] = '3d'
            # é‡ç½® AI çŠ¶æ€
            st.session_state['ai_active'] = False
            st.session_state['ai_messages'] = []
            st.session_state['ai_client'] = None
            st.rerun()
    with col2:
        if st.button("è¿‘ 7 å¤©", use_container_width=True, type="primary" if st.session_state.selected_date_range == '7d' else "secondary"):
            start_date = (datetime.now().date() - timedelta(days=7))
            end_date = datetime.now().date()
            st.session_state['data'] = load_data_by_date_range(start_date, end_date)
            st.session_state['selected_date_range'] = '7d'
            # é‡ç½® AI çŠ¶æ€
            st.session_state['ai_active'] = False
            st.session_state['ai_messages'] = []
            st.session_state['ai_client'] = None
            st.rerun()
    with col3:
        if st.button("è¿‘ 30 å¤©", use_container_width=True, type="primary" if st.session_state.selected_date_range == '30d' else "secondary"):
            start_date = (datetime.now().date() - timedelta(days=30))
            end_date = datetime.now().date()
            st.session_state['data'] = load_data_by_date_range(start_date, end_date)
            st.session_state['selected_date_range'] = '30d'
            # é‡ç½® AI çŠ¶æ€
            st.session_state['ai_active'] = False
            st.session_state['ai_messages'] = []
            st.session_state['ai_client'] = None
            st.rerun()

# å¦‚æœ session state ä¸­æ²¡æœ‰æ•°æ®ï¼Œåˆ™åŠ è½½é»˜è®¤çš„è¿‘7å¤©æ•°æ®
if not st.session_state['data']:
    start_date = (datetime.now().date() - timedelta(days=7))
    end_date = datetime.now().date()
    st.session_state['data'] = load_data_by_date_range(start_date, end_date)
    st.session_state['selected_date_range'] = '7d'

# æ˜¾ç¤ºåŠ è½½çš„æ•°æ®
if st.session_state['data']:
    st.caption(f"æ•°æ®èŒƒå›´: {min(item['Pub Date'] for item in st.session_state['data'])} è‡³ {max(item['Pub Date'] for item in st.session_state['data'])}ï¼Œå…±æ‰¾åˆ° {len(st.session_state['data'])} æ¡ç›¸å…³æ–°é—»è®°å½•")
    st.caption(f"")

    # åˆ›å»º DataFrame ä»¥ä¾¿æ›´å¥½åœ°å±•ç¤º
    import pandas as pd
    df_data = []
    for item in st.session_state['data']:
        regions_list = item["Regions"]
        regions_str = "; ".join(regions_list)
        # å¤„ç†å›½å®¶ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–é›†åˆ
        country_info = item["Country"]
        if isinstance(country_info, (set, list)):
            country_str = "; ".join(country_info)
        else:
            country_str = country_info if country_info else "æœªçŸ¥"
        df_data.append({
            "æœç´¢è¯": item["Search Term"],
            "æ ‡é¢˜": item["News Title"],
            "ä¿¡æº": item["News Source"],
            "æµé‡": item["Traffic Num"],
            "å‘å¸ƒæ—¥æœŸ": item["Pub Date"],
            "åœ°åŒº": regions_str,
            "åœ°åŒºæ•°é‡": len(regions_list),
            "å›½å®¶": country_str
        })

    df = pd.DataFrame(df_data)
    st.session_state['df'] = df

    # --- æ•°æ®æ¦‚è§ˆç»Ÿè®¡å¡ç‰‡ ---
    st.markdown("## ğŸ“Š æ•°æ®æ¦‚è§ˆ")
    stats_container = st.container(border=True)
    with stats_container:
        # ç¬¬ä¸€è¡Œç»Ÿè®¡å¡ç‰‡ï¼šæ ¸å¿ƒæŒ‡æ ‡
        col_stats1, col_stats2, col_stats3, col_stats4 = st.columns(4)
        
        with col_stats1:
            total_records = len(df)
            st.metric("æ€»æ–°é—»è®°å½•æ•°", f"{total_records:,}")
        
        with col_stats2:
            unique_countries = df["å›½å®¶"].nunique()
            st.metric("æ¶‰åŠå›½å®¶æ•°é‡", unique_countries)
        
        with col_stats3:
            avg_traffic = df["æµé‡"].mean()
            st.metric("å¹³å‡æµé‡", f"{int(avg_traffic):,}")
        
        with col_stats4:
            unique_sources = df["ä¿¡æº"].nunique()
            st.metric("æ–°é—»æ¥æºæ•°é‡", unique_sources)
        
        # ç¬¬äºŒè¡Œç»Ÿè®¡å¡ç‰‡ï¼šå›½å®¶ç›¸å…³æŒ‡æ ‡
        col_stats5, col_stats6, col_stats7, col_stats8 = st.columns(4)
        
        with col_stats5:
            # æµé‡æœ€é«˜çš„å›½å®¶
            top_traffic_country = df.groupby("å›½å®¶")["æµé‡"].sum().idxmax()
            top_traffic_value = df.groupby("å›½å®¶")["æµé‡"].sum().max()
            st.metric("æµé‡æœ€é«˜çš„å›½å®¶", top_traffic_country)
            st.caption(f"æ€»æµé‡: {int(top_traffic_value):,}")
        
        with col_stats6:
            # æ–°é—»è®°å½•æœ€å¤šçš„å›½å®¶
            top_news_country = df.groupby("å›½å®¶").size().idxmax()
            top_news_count = df.groupby("å›½å®¶").size().max()
            st.metric("æ–°é—»æœ€å¤šçš„å›½å®¶", top_news_country)
            st.caption(f"æ€»è®°å½•: {top_news_count:,}")
        
        with col_stats7:
            # å¹³å‡æ¯æ¡æ–°é—»çš„æµé‡
            avg_traffic_per_news = df["æµé‡"].sum() / len(df)
            st.metric("å¹³å‡æ¯æ¡æ–°é—»æµé‡", f"{int(avg_traffic_per_news):,}")
        
        with col_stats8:
            # ä¸åŒæœç´¢è¯çš„æ•°é‡
            unique_search_terms = df["æœç´¢è¯"].nunique()
            st.metric("ç‹¬ç‰¹æœç´¢è¯æ•°é‡", unique_search_terms)
    
    # --- ç­›é€‰åŠŸèƒ½ ---
    st.markdown("## ğŸ” æ•°æ®ç­›é€‰")
    
    # åˆ›å»ºç­›é€‰åŒºåŸŸçš„å®¹å™¨
    filter_container = st.container(border=True)
    
    with filter_container:
        st.markdown("### ç­›é€‰æ¡ä»¶")
        st.markdown("æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©ç­›é€‰æ¡ä»¶ï¼Œç³»ç»Ÿå°†å®æ—¶æ›´æ–°æ•°æ®å±•ç¤ºå’Œå¯è§†åŒ–ç»“æœ")
        
        # ç¬¬ä¸€è¡Œç­›é€‰æ¡ä»¶ï¼šä¸»è¦ç­›é€‰å™¨
        col_f1, col_f2, col_f3 = st.columns(3)
        with col_f1:
            # ä»å®é™…æ•°æ®ä¸­è·å–æ‰€æœ‰å›½å®¶åˆ—è¡¨
            all_countries = df["å›½å®¶"].unique().tolist()
            # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
            if not all_countries:
                all_countries = []
            # æ·»åŠ "æ‰€æœ‰å›½å®¶"é€‰é¡¹åˆ°å¼€å¤´
            all_countries.insert(0, "æ‰€æœ‰å›½å®¶")
            country_filter = st.selectbox(
                "ğŸŒ æŒ‰å›½å®¶ç­›é€‰", 
                all_countries, 
                index=0, 
                key="country_filter",
                help="é€‰æ‹©ç‰¹å®šå›½å®¶æˆ–æŸ¥çœ‹æ‰€æœ‰å›½å®¶çš„æ•°æ®"
            )
        with col_f2:
            region_filter = st.text_input(
                "ğŸ“ æŒ‰åœ°åŒºç­›é€‰", 
                "", 
                key="region_filter", 
                placeholder="ä¾‹å¦‚: åŠ åˆ©ç¦å°¼äºšå·, çº½çº¦",
                help="æ”¯æŒå¤šä¸ªåœ°åŒºï¼Œç”¨é€—å·åˆ†éš”"
            )
        with col_f3:
            min_traffic_filter = st.number_input(
                "ğŸ“Š æœ€ä½æµé‡ç­›é€‰", 
                min_value=0, 
                value=0, 
                step=100, 
                key="min_traffic_filter",
                help="ç­›é€‰æµé‡å¤§äºç­‰äºæŒ‡å®šå€¼çš„æ•°æ®"
            )
        
        # æ·»åŠ æ¸…é™¤ç­›é€‰æŒ‰é’®å’Œç­›é€‰ä¿¡æ¯
        col_clear, col_info = st.columns([1, 3])
        with col_clear:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤ç­›é€‰", type="secondary", use_container_width=True):
                # é‡ç½®æ‰€æœ‰ç­›é€‰å™¨
                st.session_state['country_filter'] = "æ‰€æœ‰å›½å®¶"
                st.session_state['region_filter'] = ""
                st.session_state['min_traffic_filter'] = 0
                st.rerun()
        with col_info:
            active_filters = []
            if country_filter != "æ‰€æœ‰å›½å®¶":
                active_filters.append(f"å›½å®¶: {country_filter}")
            if region_filter:
                active_filters.append(f"åœ°åŒº: {region_filter}")
            if min_traffic_filter > 0:
                active_filters.append(f"æœ€ä½æµé‡: {min_traffic_filter}")
            
            if active_filters:
                st.info(f"å½“å‰æ¿€æ´»çš„ç­›é€‰æ¡ä»¶: {', '.join(active_filters)}")
            else:
                st.info("æœªåº”ç”¨ä»»ä½•ç­›é€‰æ¡ä»¶ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®")

    df_current = df.copy()
    # å›½å®¶ç­›é€‰
    if country_filter != "æ‰€æœ‰å›½å®¶":
        df_current = df_current[df_current["å›½å®¶"] == country_filter]
    
    # åœ°åŒºç­›é€‰
    if region_filter:
        regions_to_filter = [r.strip() for r in region_filter.split(",") if r.strip()]
        mask = False
        for r in regions_to_filter:
            mask = mask | df_current["åœ°åŒº"].str.contains(r, case=False, na=False)
        df_current = df_current[mask]
    
    # æœ€ä½æµé‡ç­›é€‰
    if min_traffic_filter > 0:
        df_current = df_current[df_current["æµé‡"] >= min_traffic_filter]

    st.session_state['df_filtered'] = df_current
    
    # æ˜¾ç¤ºç­›é€‰ç»“æœç»Ÿè®¡
    filter_stats = []
    if country_filter != "æ‰€æœ‰å›½å®¶":
        filter_stats.append(f"å›½å®¶: {country_filter}")
    if region_filter:
        filter_stats.append(f"åœ°åŒº: {region_filter}")
    if min_traffic_filter > 0:
        filter_stats.append(f"æœ€ä½æµé‡: {min_traffic_filter}")
    
    if filter_stats:
        st.caption(f"å½“å‰ç­›é€‰æ¡ä»¶: {', '.join(filter_stats)} | å…± {len(df_current)} æ¡è®°å½•")
    else:
        st.caption(f"æœªåº”ç”¨ç­›é€‰æ¡ä»¶ | å…± {len(df_current)} æ¡è®°å½•")

    # --- å›½å®¶æ•°æ®å¯è§†åŒ–å›¾è¡¨ ---
    if not df_current.empty:
        st.markdown("## ğŸ“ˆ å›½å®¶æ•°æ®å¯è§†åŒ–")
        
        # åˆ›å»ºå›¾è¡¨å®¹å™¨
        chart_container = st.container(border=True)
        
        with chart_container:
            # è®¾ç½®å›¾è¡¨æ ·å¼ï¼Œç¡®ä¿è§†è§‰ä¸€è‡´æ€§
            sns.set_style("darkgrid")
            sns.set_palette("deep")
            sns.set_context("notebook", font_scale=1.0)
            
            # è®¾ç½®ç»Ÿä¸€çš„å›¾è¡¨é…ç½®
            plt.rcParams.update({
                'font.size': 12,
                'axes.titlesize': 14,
                'axes.labelsize': 12,
                'xtick.labelsize': 10,
                'ytick.labelsize': 10,
                'legend.fontsize': 10,
                'figure.figsize': (10, 6)
            })
            
            # ç¬¬ä¸€è¡Œå›¾è¡¨ï¼šå›½å®¶æ–°é—»æ•°é‡å’Œå¹³å‡æµé‡
            st.markdown("### Country Core Metrics Comparison")
            col_chart1, col_chart2 = st.columns(2)
            
            with col_chart1:
                # æŒ‰å›½å®¶åˆ†ç»„ç»Ÿè®¡æ–°é—»æ•°é‡
                country_news_count = df_current.groupby("å›½å®¶").size().reset_index(name="æ–°é—»æ•°é‡")
                country_news_count = country_news_count.sort_values(by="æ–°é—»æ•°é‡", ascending=False).head(10)
                
                # åˆ›å»ºå›¾è¡¨
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.barplot(x="æ–°é—»æ•°é‡", y="å›½å®¶", data=country_news_count, palette="viridis", ax=ax)
                ax.set_xlabel("Number of News Records")
                ax.set_ylabel("å›½å®¶")
                
                # æ ¹æ®ç­›é€‰æ¡ä»¶è°ƒæ•´æ ‡é¢˜
                if country_filter == "æ‰€æœ‰å›½å®¶":
                    ax.set_title("News Records by Country")
                else:
                    ax.set_title(f"{country_filter} æ–°é—»è®°å½•æ•°é‡")
                
                # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, v in enumerate(country_news_count["æ–°é—»æ•°é‡"]):
                    ax.text(v + 0.5, i, str(v), va='center', fontsize=10)
                
                # è®¾ç½®å›¾è¡¨è¾¹è·
                plt.tight_layout()
                st.pyplot(fig)
            
            with col_chart2:
                # æŒ‰å›½å®¶åˆ†ç»„è®¡ç®—å¹³å‡æµé‡
                country_avg_traffic = df_current.groupby("å›½å®¶")["æµé‡"].mean().reset_index(name="å¹³å‡æµé‡")
                country_avg_traffic["å¹³å‡æµé‡"] = country_avg_traffic["å¹³å‡æµé‡"].astype(int)
                country_avg_traffic = country_avg_traffic.sort_values(by="å¹³å‡æµé‡", ascending=False).head(10)
                
                # åˆ›å»ºå›¾è¡¨
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.barplot(x="å¹³å‡æµé‡", y="å›½å®¶", data=country_avg_traffic, palette="plasma", ax=ax)
                ax.set_xlabel("Average Traffic")
                ax.set_ylabel("å›½å®¶")
                
                # æ ¹æ®ç­›é€‰æ¡ä»¶è°ƒæ•´æ ‡é¢˜
                if country_filter == "æ‰€æœ‰å›½å®¶":
                    ax.set_title("Average Traffic by Country")
                else:
                    ax.set_title(f"{country_filter} å¹³å‡æµé‡")
                
                # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, v in enumerate(country_avg_traffic["å¹³å‡æµé‡"]):
                    ax.text(v + 0.5, i, f"{v:,}", va='center', fontsize=10)
                
                # è®¾ç½®å›¾è¡¨è¾¹è·
                plt.tight_layout()
                st.pyplot(fig)

            # ç¬¬äºŒè¡Œå›¾è¡¨ï¼šæµé‡è¶‹åŠ¿å’Œæ–°é—»æ¥æºåˆ†å¸ƒ
            st.markdown("### Traffic Trend and Source Analysis")
            col_chart3, col_chart4 = st.columns(2)
            
            with col_chart3:
                # æŒ‰æ—¥æœŸçš„æµé‡è¶‹åŠ¿ï¼ˆå¦‚æœé€‰æ‹©äº†å•ä¸ªå›½å®¶æˆ–æ•°æ®é‡è¶³å¤Ÿï¼‰
                if len(df_current) > 5:
                    # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—æ€»æµé‡
                    daily_traffic = df_current.groupby("å‘å¸ƒæ—¥æœŸ")["æµé‡"].sum().reset_index(name="æ€»æµé‡")
                    daily_traffic = daily_traffic.sort_values(by="å‘å¸ƒæ—¥æœŸ")
                    
                    # åˆ›å»ºå›¾è¡¨
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.lineplot(x="å‘å¸ƒæ—¥æœŸ", y="æ€»æµé‡", data=daily_traffic, marker='o', ax=ax, color="#4C72B0")
                    ax.set_xlabel("Date")
                    ax.set_ylabel("Total Traffic")
                    
                    # æ ¹æ®ç­›é€‰æ¡ä»¶è°ƒæ•´æ ‡é¢˜
                    if country_filter == "æ‰€æœ‰å›½å®¶":
                        ax.set_title("Global Traffic Trend")
                    else:
                        ax.set_title(f"{country_filter} æµé‡è¶‹åŠ¿")
                    
                    # ä¼˜åŒ–æ—¥æœŸæ˜¾ç¤º
                    plt.xticks(rotation=45, fontsize=8)
                    plt.grid(True, alpha=0.3)
                    
                    # è®¾ç½®å›¾è¡¨è¾¹è·
                    plt.tight_layout()
                    st.pyplot(fig)
                else:
                    st.info("æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•æ˜¾ç¤ºæµé‡è¶‹åŠ¿")
            
            with col_chart4:
                # æ–°é—»æ¥æºåˆ†å¸ƒé¥¼å›¾
                st.markdown("#### News Source Distribution")
                source_distribution = df_current.groupby("ä¿¡æº").size().reset_index(name="æ•°é‡")
                source_distribution = source_distribution.sort_values(by="æ•°é‡", ascending=False).head(8)
                
                # å¦‚æœæœ‰è¶…è¿‡8ä¸ªæ¥æºï¼Œå°†å‰©ä½™çš„åˆå¹¶ä¸º"å…¶ä»–"
                if len(source_distribution) >= 8:
                    top_sources = source_distribution.head(7)
                    other_count = source_distribution.tail(len(source_distribution) - 7)["æ•°é‡"].sum()
                    if other_count > 0:
                        top_sources.loc[len(top_sources)] = ["å…¶ä»–", other_count]
                    source_distribution = top_sources
                
                # åˆ›å»ºé¥¼å›¾
                fig, ax = plt.subplots(figsize=(10, 6))
                ax.pie(source_distribution["æ•°é‡"], labels=source_distribution["ä¿¡æº"], autopct='%1.1f%%', startangle=90)
                ax.axis('equal')  # ç¡®ä¿é¥¼å›¾æ˜¯åœ†å½¢
                
                # æ ¹æ®ç­›é€‰æ¡ä»¶è°ƒæ•´æ ‡é¢˜
                if country_filter == "æ‰€æœ‰å›½å®¶":
                    ax.set_title("Global News Source Distribution")
                else:
                    ax.set_title(f"{country_filter} æ–°é—»æ¥æºåˆ†å¸ƒ")
                
                # è®¾ç½®å›¾è¡¨è¾¹è·
                plt.tight_layout()
                st.pyplot(fig)
            
            # ç¬¬ä¸‰è¡Œå›¾è¡¨ï¼šæµé‡åˆ†å¸ƒå’Œåœ°åŒºåˆ†å¸ƒ
            st.markdown("### Traffic and Regional Distribution Analysis")
            col_chart5, col_chart6 = st.columns(2)
            
            with col_chart5:
                # æµé‡åˆ†å¸ƒç®±çº¿å›¾
                st.markdown("#### Traffic Distribution")
                if country_filter == "æ‰€æœ‰å›½å®¶":
                    # å¤šå›½å®¶æµé‡åˆ†å¸ƒå¯¹æ¯”
                    if len(df_current["å›½å®¶"].unique()) > 1:
                        fig, ax = plt.subplots(figsize=(10, 6))
                        sns.boxplot(x="å›½å®¶", y="æµé‡", data=df_current, ax=ax, palette="Set3")
                        ax.set_xlabel("å›½å®¶")
                        ax.set_ylabel("Traffic")
                        ax.set_title("Traffic Distribution by Country")
                        plt.xticks(rotation=45, fontsize=8)
                        plt.tight_layout()
                        st.pyplot(fig)
                    else:
                        # å•ä¸ªå›½å®¶æµé‡åˆ†å¸ƒ
                        fig, ax = plt.subplots(figsize=(10, 6))
                        sns.boxplot(y="æµé‡", data=df_current, ax=ax, palette="Set3")
                        ax.set_ylabel("Traffic")
                        ax.set_title(f"{country_filter} æµé‡åˆ†å¸ƒ")
                        plt.tight_layout()
                        st.pyplot(fig)
                else:
                    # å•ä¸ªå›½å®¶ä¸åŒåœ°åŒºçš„æµé‡åˆ†å¸ƒ
                    if "åœ°åŒº" in df_current.columns and len(df_current["åœ°åŒº"].unique()) > 1:
                        fig, ax = plt.subplots(figsize=(10, 6))
                        # åªæ˜¾ç¤ºæµé‡æœ€å¤§çš„å‰10ä¸ªåœ°åŒº
                        top_regions = df_current.groupby("åœ°åŒº")["æµé‡"].sum().nlargest(10).index
                        df_top_regions = df_current[df_current["åœ°åŒº"].isin(top_regions)]
                        sns.boxplot(x="åœ°åŒº", y="æµé‡", data=df_top_regions, ax=ax, palette="Set3")
                        ax.set_xlabel("Region")
                        ax.set_ylabel("Traffic")
                        ax.set_title(f"{country_filter} å„åœ°åŒºæµé‡åˆ†å¸ƒ")
                        plt.xticks(rotation=45, fontsize=8)
                        plt.tight_layout()
                        st.pyplot(fig)
                    else:
                        # å•ä¸ªå›½å®¶æµé‡åˆ†å¸ƒï¼ˆæ— åœ°åŒºæ•°æ®æˆ–åœ°åŒºæ•°æ®ä¸è¶³ï¼‰
                        fig, ax = plt.subplots(figsize=(10, 6))
                        sns.boxplot(y="æµé‡", data=df_current, ax=ax, palette="Set3")
                        ax.set_ylabel("æµé‡")
                        ax.set_title(f"{country_filter} æµé‡åˆ†å¸ƒ")
                        plt.tight_layout()
                        st.pyplot(fig)
            
            with col_chart6:
                # å›½å®¶åœ°åŒºåˆ†å¸ƒï¼ˆä»…å½“é€‰æ‹©å•ä¸ªå›½å®¶æ—¶ï¼‰
                if country_filter != "æ‰€æœ‰å›½å®¶" and len(df_current) > 0:
                    # æŒ‰åœ°åŒºåˆ†ç»„ç»Ÿè®¡æ–°é—»æ•°é‡
                    region_news_count = df_current.groupby("åœ°åŒº").size().reset_index(name="æ–°é—»æ•°é‡")
                    region_news_count = region_news_count.sort_values(by="æ–°é—»æ•°é‡", ascending=False).head(10)
                    
                    # åˆ›å»ºå›¾è¡¨
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.barplot(x="æ–°é—»æ•°é‡", y="åœ°åŒº", data=region_news_count, palette="RdBu_r", ax=ax)
                    ax.set_xlabel("Number of News Records")
                    ax.set_ylabel("Region")
                    ax.set_title(f"News Records by Region")
                    
                    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
                    for i, v in enumerate(region_news_count["æ–°é—»æ•°é‡"]):
                        ax.text(v + 0.5, i, str(v), va='center', fontsize=10)
                    
                    # è®¾ç½®å›¾è¡¨è¾¹è·
                    plt.tight_layout()
                    st.pyplot(fig)
                else:
                    # å½“é€‰æ‹©æ‰€æœ‰å›½å®¶æ—¶ï¼Œæ˜¾ç¤ºåœ°åŒºæ•°é‡åˆ†å¸ƒ
                    region_count = df_current.groupby("å›½å®¶")["åœ°åŒºæ•°é‡"].mean().reset_index(name="å¹³å‡åœ°åŒºæ•°é‡")
                    region_count = region_count.sort_values(by="å¹³å‡åœ°åŒºæ•°é‡", ascending=False).head(10)
                    
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.barplot(x="å¹³å‡åœ°åŒºæ•°é‡", y="å›½å®¶", data=region_count, palette="Purples", ax=ax)
                    ax.set_xlabel("Average Number of Regions")
                    ax.set_ylabel("å›½å®¶")
                    ax.set_title("Average Regions Involved by Country")
                    
                    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
                    for i, v in enumerate(region_count["å¹³å‡åœ°åŒºæ•°é‡"]):
                        ax.text(v + 0.05, i, f"{v:.1f}", va='center', fontsize=10)
                    
                    # è®¾ç½®å›¾è¡¨è¾¹è·
                    plt.tight_layout()
                    st.pyplot(fig)
            
            # é‡ç½®Matplotlibè®¾ç½®ï¼Œé¿å…å½±å“åç»­å›¾è¡¨
            plt.close('all')
            sns.reset_orig()
    else:
        st.info("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®å¯ç”¨äºå¯è§†åŒ–")

    # --- å§‹ç»ˆæ˜¾ç¤ºåŸå§‹è¡¨æ ¼ï¼ˆå¯æ’åºï¼‰---
    st.subheader("ğŸ“Š æ•°æ®è¡¨æ ¼")
    if region_filter or min_traffic_filter > 0:
        st.caption(f"ç­›é€‰ç»“æœ: å…± {len(df_current)} æ¡è®°å½•")
    else:
        st.caption(f"å…± {len(df)} æ¡è®°å½•")
    
    # è°ƒæ•´åˆ—é¡ºåºï¼Œå°†å›½å®¶å’Œåœ°åŒºåˆ—æ”¾åœ¨å‰é¢
    columns = [
        "å›½å®¶", "åœ°åŒº", "æœç´¢è¯", "æ ‡é¢˜", "ä¿¡æº", "æµé‡", "å‘å¸ƒæ—¥æœŸ", "åœ°åŒºæ•°é‡"
    ]
    
    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
    available_columns = [col for col in columns if col in df_current.columns]
    
    # æ˜¾ç¤ºè°ƒæ•´åçš„è¡¨æ ¼
    st.dataframe(
        df_current[available_columns], 
        use_container_width=True, 
        height=600,  # å›ºå®šé«˜åº¦é¿å…é¡µé¢å¤ªé•¿
        column_config={
            "å›½å®¶": st.column_config.Column(
                "å›½å®¶",
                width="medium",
                help="æ–°é—»æ¥æºå›½å®¶"
            ),
            "åœ°åŒº": st.column_config.Column(
                "åœ°åŒº",
                width="wide",
                help="æ–°é—»æ¥æºåœ°åŒº"
            ),
            "æœç´¢è¯": st.column_config.Column(
                "æœç´¢è¯",
                width="medium",
                help="çƒ­ç‚¹æœç´¢è¯"
            ),
            "æ ‡é¢˜": st.column_config.Column(
                "æ–°é—»æ ‡é¢˜",
                width="large",
                help="æ–°é—»æ ‡é¢˜"
            ),
            "ä¿¡æº": st.column_config.Column(
                "æ–°é—»æ¥æº",
                width="medium",
                help="æ–°é—»å‘å¸ƒæ¥æº"
            ),
            "æµé‡": st.column_config.NumberColumn(
                "æµé‡",
                width="small",
                help="æ–°é—»æµé‡æ•°å€¼",
                format="%d"
            ),
            "å‘å¸ƒæ—¥æœŸ": st.column_config.DateColumn(
                "å‘å¸ƒæ—¥æœŸ",
                width="small",
                help="æ–°é—»å‘å¸ƒæ—¥æœŸ"
            ),
            "åœ°åŒºæ•°é‡": st.column_config.NumberColumn(
                "æ¶‰åŠåœ°åŒºæ•°é‡",
                width="small",
                help="è¯¥æ–°é—»æ¶‰åŠçš„åœ°åŒºæ•°é‡"
            )
        }
    )

    # --- AI åŠŸèƒ½åŒºåŸŸ ---
    if st.session_state['data']:  # ä»…å½“æœ‰æ•°æ®æ—¶æ‰æ˜¾ç¤º AI åŠŸèƒ½
        st.subheader("ğŸ¤– AI åˆ†æåŠŸèƒ½")

        # AI é…ç½®è¾“å…¥ï¼ˆç´§å‡‘å¸ƒå±€ï¼‰
        #col_ai1, col_ai2, col_ai3 = st.columns([3, 2, 1])
        #with col_ai1:
        #    ai_endpoint = st.text_input("Endpoint", value=DEFAULT_ENDPOINT, key="ai_endpoint")
        #with col_ai2:
        #    ai_api_key = st.text_input("API Key", value=DEFAULT_API_KEY, type="password", key="ai_api_key")
        #with col_ai3:
        #    ai_model = st.text_input("Model", value=DEFAULT_MODEL, key="ai_model")

        # AI é…ç½®è¾“å…¥
        ai_endpoint         = DEFAULT_ENDPOINT
        ai_api_key          = DEFAULT_API_KEY
        ai_model            = DEFAULT_MODEL

        if df_current.empty:
                st.error("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ•°æ®å¯ä¾›åˆ†æ")
        elif not ai_api_key.strip():
            st.error("è¯·å…ˆå¡«å†™ API Key")
        else:
            # ç”Ÿæˆç®€åŒ–è¡¨æ ¼ï¼ˆç”¨äºå‘é€ç»™ AIï¼‰
            markdown_table = generate_simple_markdown_table(df_current)
            # st.write("```" +markdown_table+ "```")
            # æ‹¼æ¥å‘é€ç»™ AI çš„å†…å®¹
            user_prompt_with_table = DEFAULT_USER_PROMPT + "\n\n" + markdown_table

            # ä¼°ç®— Token
            try:
                system_tokens = estimate_tokens(DEFAULT_SYSTEM_PROMPT, ai_model)
                user_tokens = estimate_tokens(user_prompt_with_table, ai_model)
                total_tokens = system_tokens + user_tokens
            except Exception as e:
                st.warning(f"Token ä¼°ç®—å¤±è´¥ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ä¼°ç®—ï¼‰: {e}")
                # fallback
                total_tokens = estimate_tokens(
                    DEFAULT_SYSTEM_PROMPT + "\n\n" + user_prompt_with_table, 
                    "gpt-4o"
                )
            # æ˜¾ç¤º Token ä¿¡æ¯ï¼ˆæŒä¹…æ˜¾ç¤ºï¼‰
                st.session_state['token_count'] = total_tokens
                st.write(f"ğŸ”¹ ä¼°ç®— Token æ•°é‡: {total_tokens}")

                
        # å¯åŠ¨åˆ†ææŒ‰é’®
        if st.button("ğŸš€ å¯åŠ¨ AI åˆ†æ", type="primary"):
            if total_tokens > DEFAULT_MAX_TOKENS:
                st.warning(f"âš ï¸ è¶…è¿‡ {DEFAULT_MAX_TOKENS} tokens é™åˆ¶ï¼å¯èƒ½å½±å“åˆ†ææ•ˆæœã€‚")
                if st.button("â— ç¡®è®¤ç»§ç»­åˆ†æ", type="secondary", key="confirm_overlimit"):
                    # åˆå§‹åŒ–å®¢æˆ·ç«¯å¹¶å¯åŠ¨åˆ†æ
                    try:
                        client = OpenAI(base_url=ai_endpoint, api_key=ai_api_key)
                        st.session_state['ai_client'] = client
                        # å‘é€ç»™ AI çš„æ¶ˆæ¯
                        st.session_state['ai_messages'] = [
                            {"role": "system", "content": DEFAULT_SYSTEM_PROMPT},
                            {"role": "user", "content": user_prompt_with_table} # åŒ…å«è¡¨æ ¼
                        ]
                        st.session_state['ai_active'] = True
                        st.rerun()
                    except Exception as e:
                        st.error(f"åˆå§‹åŒ– AI å®¢æˆ·ç«¯å¤±è´¥: {e}")
            else:
                # æœªè¶…é™ï¼Œç›´æ¥å¯åŠ¨
                try:
                    client = OpenAI(base_url=ai_endpoint, api_key=ai_api_key)
                    st.session_state['ai_client'] = client
                    # å‘é€ç»™ AI çš„æ¶ˆæ¯
                    st.session_state['ai_messages'] = [
                        {"role": "system", "content": DEFAULT_SYSTEM_PROMPT},
                        {"role": "user", "content": user_prompt_with_table} # åŒ…å«è¡¨æ ¼
                    ]
                    st.session_state['ai_active'] = True
                    st.rerun()
                except Exception as e:
                    st.error(f"åˆå§‹åŒ– AI å®¢æˆ·ç«¯å¤±è´¥: {e}")

        # --- AI å¯¹è¯åŒºåŸŸ ---
        if st.session_state['ai_active'] and st.session_state['ai_client']:
            # æ‰‹åŠ¨æ·»åŠ ä¸€ç‚¹é—´è·
            st.divider()
            st.subheader("ğŸ’¬ AI å¯¹è¯")

            # æ˜¾ç¤ºå·²æœ‰å®Œæ•´å¯¹è¯
            messages = st.session_state['ai_messages']
            for msg in messages:
                if msg["role"] == "user":
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆå§‹æ¶ˆæ¯ï¼ˆåŒ…å«è¡¨æ ¼çš„æ¶ˆæ¯ï¼‰
                    if DEFAULT_TABLE_CONTENT_PLACEHOLDER in msg['content'] or "news_title | source" in msg['content']:
                        # åˆå§‹æ¶ˆæ¯åªæ˜¾ç¤ºæç¤ºè¯éƒ¨åˆ†ï¼Œä¸æ˜¾ç¤ºè¡¨æ ¼
                        st.markdown(f"ğŸ§‘â€ğŸ’» **You** {DEFAULT_USER_PROMPT}")
                    else:
                        # åç»­æ¶ˆæ¯æ˜¾ç¤ºå®é™…ç”¨æˆ·è¾“å…¥
                        st.markdown(f"ğŸ§‘â€ğŸ’» **You:** {msg['content']}")
                elif msg["role"] == "assistant":
                    st.markdown(f"ğŸ‘¾ **AI:** {msg['content']}")

            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„ AI å›å¤ï¼ˆå³æœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œä½†æ²¡æœ‰å¯¹åº”çš„ AI å›å¤ï¼‰
            last_user_message_idx = -1
            for i in range(len(messages) - 1, -1, -1):
                if messages[i]["role"] == "user":
                    last_user_message_idx = i
                    break

            last_ai_message_idx = -1
            for i in range(len(messages) - 1, -1, -1):
                if messages[i]["role"] == "assistant":
                    last_ai_message_idx = i
                    break

            # å¦‚æœæœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œä¸”æ²¡æœ‰ AI å›å¤ï¼Œåˆ™æ­£åœ¨ç”Ÿæˆ
            if last_user_message_idx > last_ai_message_idx:
                # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦ç”¨äºæµå¼æ˜¾ç¤º AI å›å¤
                ai_response_placeholder = st.empty()
                ai_response_placeholder.markdown("ğŸ§  **AI æ­£åœ¨æ€è€ƒä¸­...**")

                try:
                    stream = st.session_state['ai_client'].chat.completions.create(
                        model=ai_model,
                        messages=messages, # åŒ…å«å®Œæ•´å†å²ï¼ˆåŒ…å«è¡¨æ ¼ï¼‰
                        stream=True,
                    )
                    full_response = ""
                    for chunk in stream:
                        if chunk.choices[0].delta.content is not None:
                            full_response += chunk.choices[0].delta.content
                            # å®æ—¶æ›´æ–°å ä½ç¬¦
                            ai_response_placeholder.markdown(f"ğŸ¤– **AI:** {full_response}")
                    
                    # å¾ªç¯ç»“æŸåï¼Œä¿å­˜å®Œæ•´çš„ AI å›å¤
                    st.session_state['ai_messages'].append({"role": "assistant", "content": full_response})
                    # é‡æ–°è¿è¡Œä»¥åˆ·æ–°ç•Œé¢ï¼Œæ˜¾ç¤ºæ–°æ¶ˆæ¯
                    st.rerun()
                except Exception as e:
                    st.error(f"AI è°ƒç”¨å¤±è´¥: {e}")
                    # å¯ä»¥é€‰æ‹©ç§»é™¤å¾…å¤„ç†çš„æ¶ˆæ¯ï¼Œæˆ–ä¿ç•™ä»¥ä¾¿é‡è¯•
                    # st.session_state['ai_messages'].pop() # ç§»é™¤æœ€åçš„ç”¨æˆ·æ¶ˆæ¯
            # å¦‚æœæœ‰ AI å›å¤ï¼Œä½†æœªæ˜¾ç¤ºï¼ˆæ¯”å¦‚åˆšä»æµå¼ç»“æŸï¼‰ï¼Œåˆ™æ˜¾ç¤ºå®ƒ
            elif last_ai_message_idx == len(messages) - 1:
                # æœ€åä¸€æ¡æ˜¯ AI æ¶ˆæ¯ï¼Œä½†ä¸Šé¢çš„å¾ªç¯å·²ç»æ˜¾ç¤ºè¿‡äº†ï¼Œæ— éœ€é‡å¤
                # è¿™ä¸ªåˆ†æ”¯ä¸»è¦æ˜¯ä¸ºäº†é€»è¾‘å®Œæ•´æ€§
                pass

            # ç»§ç»­å¯¹è¯è¾“å…¥
            user_input = st.chat_input("ç»§ç»­ä¸ AI è®¨è®ºè¿™äº›çƒ­ç‚¹...")
            if user_input:
                st.session_state['ai_messages'].append({"role": "user", "content": user_input})
                # é‡æ–°è¿è¡Œä»¥è§¦å‘AIå›å¤ç”Ÿæˆé€»è¾‘
                st.rerun()

else:
    st.info("åœ¨æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•æ•°æ®æˆ–ç›¸å…³æ–‡ä»¶ã€‚")

# å¯é€‰ï¼šæä¾›ä¸€ä¸ªæ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
# if st.button("Refresh Data"):
#     start_date = (datetime.now().date() - timedelta(days=7)) # æˆ–æ ¹æ®å½“å‰é€‰æ‹©çš„èŒƒå›´
#     end_date = datetime.now().date()
#     st.session_state['data'] = load_data_by_date_range(start_date, end_date)
#     st.rerun()
import streamlit as st
import os
import json
from datetime import datetime, timedelta
from collections import defaultdict
import tiktoken  # ç”¨äºä¼°ç®— token æ•°é‡
import openai
from openai import OpenAI
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import requests

# å¯¼å…¥é…ç½®æ¨¡å—
from config import get_config
config = get_config()

# å¯¼å…¥æ¨¡å‹ä¾›åº”å•†é…ç½®
from model_providers import (
    get_provider_config,
    get_provider_names,
    get_provider_default_models,
    get_provider_default_endpoint
)

# --- è®¾ç½®å·¥ä½œç›®å½•ä¸ºè„šæœ¬æ‰€åœ¨ç›®å½• ---
# è·å–å½“å‰è„šæœ¬çš„ç»å¯¹è·¯å¾„
script_dir = os.path.dirname(os.path.abspath(__file__))
# åˆ‡æ¢åˆ°è„šæœ¬æ‰€åœ¨ç›®å½•
os.chdir(script_dir)
# st.write(f"å·¥ä½œç›®å½•å·²è®¾ç½®ä¸º: {os.getcwd()}") # å¯é€‰ï¼šæ‰“å°å½“å‰å·¥ä½œç›®å½•ä»¥ç¡®è®¤


# --- é…ç½® ---
# 1. æŒ‡å®šåŒ…å« JSON æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„è·¯å¾„)
FOLDER_PATH = 'JSONs'  # <--- ä¿®æ”¹æ­¤è·¯å¾„
JSON_FILENAME_PATTERN = 'trends_{}.json' # JSON æ–‡ä»¶åçš„æ¨¡å¼ï¼Œ{} ä¼šè¢«æ—¥æœŸæ›¿æ¢

# å¯¼å…¥é…ç½®å’Œå‡­è¯æ¨¡å—
# ä»configä¸­è·å–æç¤ºè¯é…ç½®
AI_DEFAULT_USER_PROMPT = config.PROMPTS.AI_DEFAULT_USER_PROMPT
AI_DEFAULT_TABLE_CONTENT_PLACEHOLDER = config.PROMPTS.AI_DEFAULT_TABLE_CONTENT_PLACEHOLDER
AI_DEFAULT_SYSTEM_PROMPT = config.PROMPTS.AI_DEFAULT_SYSTEM_PROMPT
from credentials import (
    MODEL_API_KEY,
    MODEL_API_ENDPOINT,
    MODEL_NAME
)

# --- AI é…ç½® ---
# ä½ å¯ä»¥åœ¨è¿™é‡Œä¿®æ”¹é»˜è®¤å€¼ï¼Œä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡
DEFAULT_ENDPOINT = MODEL_API_ENDPOINT  # ä»å‡­è¯æ¨¡å—å¯¼å…¥
DEFAULT_API_KEY = MODEL_API_KEY  # ä»å‡­è¯æ¨¡å—å¯¼å…¥
DEFAULT_MODEL = MODEL_NAME  # ä»å‡­è¯æ¨¡å—å¯¼å…¥
DEFAULT_MAX_TOKENS = 128*1024  # 64K tokens
DEFAULT_USER_PROMPT = AI_DEFAULT_USER_PROMPT  # ä»æç¤ºè¯æ¨¡å—å¯¼å…¥
DEFAULT_TABLE_CONTENT_PLACEHOLDER = AI_DEFAULT_TABLE_CONTENT_PLACEHOLDER  # ä»æç¤ºè¯æ¨¡å—å¯¼å…¥
DEFAULT_SYSTEM_PROMPT = AI_DEFAULT_SYSTEM_PROMPT  # ä»æç¤ºè¯æ¨¡å—å¯¼å…¥
DEFAULT_SUPPLIER = "OpenAI"  # é»˜è®¤ä¾›åº”å•†


# --- å‡½æ•°å®šä¹‰ ---
def parse_pub_date(pub_date_str):
    """è§£æ ISO 8601 æ ¼å¼çš„ pubDate å­—ç¬¦ä¸²ä¸º datetime å¯¹è±¡"""
    # ç¤ºä¾‹æ ¼å¼: "2025-10-21T17:20:00-07:00", "2025-12-30"
    try:
        # Python çš„ fromisoformat åœ¨ 3.11+ ä¸­æ”¯æŒå¸¦æ—¶åŒºçš„æ ¼å¼ï¼Œå¯¹äºæ—§ç‰ˆæœ¬ï¼Œéœ€è¦æ‰‹åŠ¨å¤„ç†
        # ç§»é™¤æ—¶åŒºåç§»éƒ¨åˆ†å¹¶æ‰‹åŠ¨è§£æ
        # æ ¼å¼ä¸º YYYY-MM-DDTHH:MM:SS+HH:MM æˆ– -HH:MM
        # è¿™é‡Œç®€å•åœ°ç§»é™¤æ—¶åŒºéƒ¨åˆ†ï¼Œåªå–æ—¥æœŸæ—¶é—´
        # æ›´ç²¾ç¡®çš„å¤„ç†å¯ä»¥ä½¿ç”¨ dateutil åº“
        # ä¸ºäº†å…¼å®¹æ€§ï¼Œè¿™é‡Œæ‰‹åŠ¨åˆ†å‰²
        if pub_date_str:
            # æ£€æŸ¥æ˜¯å¦åŒ…å«æ—¶é—´éƒ¨åˆ†
            if 'T' in pub_date_str:
                # åˆ†å‰²æ—¥æœŸæ—¶é—´å’Œæ—¶åŒº
                dt_part = pub_date_str.split('T')[0]
                time_part = pub_date_str.split('T')[1].split('-')[0].split('+')[0] # ç§»é™¤æ—¶åŒº
                full_dt_str = f"{dt_part}T{time_part}"
                # ç›´æ¥è§£æå®Œæ•´çš„æ—¥æœŸæ—¶é—´å­—ç¬¦ä¸²ï¼Œä¸è¿›è¡Œé¢å¤–çš„åˆ†å‰²
                dt = datetime.fromisoformat(full_dt_str.replace('Z', '+00:00'))
            else:
                # ç®€å•æ—¥æœŸæ ¼å¼ï¼Œå¦‚ "2025-12-30"
                dt = datetime.strptime(pub_date_str, '%Y-%m-%d')
            return dt.date()
    except ValueError:
        try:
            # å°è¯•å…¶ä»–å¯èƒ½çš„æ ¼å¼
            dt = datetime.strptime(pub_date_str.split('T')[0], '%Y-%m-%d')
            return dt.date()
        except ValueError:
            st.warning(f"æ— æ³•è§£ææ—¥æœŸå­—ç¬¦ä¸²: {pub_date_str}")
            return None
    return None

def is_date_in_range(pub_date_str, start_date, end_date):
    """æ£€æŸ¥ pubDate æ˜¯å¦åœ¨æŒ‡å®šèŒƒå›´å†…"""
    parsed_date = parse_pub_date(pub_date_str)
    if parsed_date:
        return start_date <= parsed_date <= end_date
    return False

def load_and_process_file_for_date(target_date, results_list):
    """åŠ è½½å¹¶å¤„ç†æŒ‡å®šæ—¥æœŸçš„ JSON æ–‡ä»¶ï¼Œå°†æ¯ä¸ªæ–°é—»é¡¹ä½œä¸ºä¸€è¡Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­"""
    filename = JSON_FILENAME_PATTERN.format(target_date.strftime('%Y-%m-%d'))
    
    # æœç´¢æ‰€æœ‰å›½å®¶å­æ–‡ä»¶å¤¹ä¸­çš„JSONæ–‡ä»¶
    search_paths = [FOLDER_PATH]
    
    # æ·»åŠ æ‰€æœ‰å›½å®¶å­æ–‡ä»¶å¤¹
    try:
        for item in os.listdir(FOLDER_PATH):
            item_path = os.path.join(FOLDER_PATH, item)
            if os.path.isdir(item_path):
                search_paths.append(item_path)
    except Exception as e:
        st.warning(f"æ— æ³•è¯»å–æ–‡ä»¶å¤¹ç»“æ„: {e}")
    
    # å¤„ç†æ¯ä¸ªå¯èƒ½çš„æ–‡ä»¶è·¯å¾„
    for search_path in search_paths:
        # æ£€æŸ¥æ‰€æœ‰åŒ¹é…æ—¥æœŸå‰ç¼€çš„æ–‡ä»¶ï¼ŒåŒ…æ‹¬å¸¦å›½å®¶åç¼€çš„
        base_name, ext = os.path.splitext(filename)
        matching_files = []
        
        try:
            # è·å–è¯¥è·¯å¾„ä¸‹æ‰€æœ‰ä»¥base_nameå¼€å¤´çš„æ–‡ä»¶
            all_files = os.listdir(search_path)
            matching_files = [f for f in all_files if f.startswith(base_name)]
        except Exception as e:
            continue
        
        for matching_file in matching_files:
                file_path = os.path.join(search_path, matching_file)
                
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                except json.JSONDecodeError as e:
                    st.error(f"è§£ç  JSON æ–‡ä»¶é”™è¯¯ {file_path}: {e}")
                    continue
                except FileNotFoundError:
                    # è¿™ä¸ªé”™è¯¯ç†è®ºä¸Šä¸ä¼šè§¦å‘ï¼Œå› ä¸ºä¸Šé¢å·²ç»æ£€æŸ¥äº†æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    st.error(f"æ–‡ä»¶æœªæ‰¾åˆ° (æ­¤é”™è¯¯ä¸åº”å‡ºç°): {file_path}")
                    continue
                except Exception as e:
                    st.error(f"è¯»å–æ–‡ä»¶æ—¶å‘ç”Ÿæ„å¤–é”™è¯¯ {file_path}: {e}")
                    continue

                if not isinstance(data, list):
                    st.warning(f"è­¦å‘Š: {file_path} ä¸­çš„æ•°æ®ä¸æ˜¯åˆ—è¡¨ã€‚è·³è¿‡ã€‚")
                    continue

                # ä»æ–‡ä»¶å¤¹è·¯å¾„æå–å›½å®¶ä¿¡æ¯
                # ä¾‹å¦‚ï¼šJSONs/India/trends_2025-10-14.json â†’ "India"
                folder_country = None
                # æ£€æŸ¥search_pathæ˜¯å¦æ˜¯FOLDER_PATHçš„å­ç›®å½•
                if search_path != FOLDER_PATH:
                    # è·å–search_pathç›¸å¯¹äºFOLDER_PATHçš„è·¯å¾„
                    relative_path = os.path.relpath(search_path, FOLDER_PATH)
                    # è·å–ç›¸å¯¹è·¯å¾„çš„ç¬¬ä¸€éƒ¨åˆ†ï¼Œå³å›½å®¶åç§°
                    folder_country = relative_path.split(os.sep)[0]
                    # éªŒè¯è¿™ä¸ªå›½å®¶åç§°æ˜¯å¦çœŸçš„å­˜åœ¨
                    if not os.path.isdir(os.path.join(FOLDER_PATH, folder_country)):
                        folder_country = None

                for item in data:
                    # 1. ç­›é€‰ traffic_num (è¿™é‡Œå‡è®¾æ˜¯ traffic_numï¼ŒåŸä»£ç æ˜¯ traffic)
                    # è°ƒæ•´é˜ˆå€¼ä¸º0ï¼Œæ˜¾ç¤ºæ‰€æœ‰æµé‡æ•°æ®
                    if item.get('traffic_num', 0) < 0: # å¯ä»¥æ ¹æ®éœ€è¦è°ƒæ•´é˜ˆå€¼
                        continue

                    # 2. ç­›é€‰ pub_date æ˜¯å¦ä¸ºå½“å¤© (å› ä¸ºæ–‡ä»¶åå·²ç»é™å®šäº†æ—¥æœŸèŒƒå›´)
                    # æˆ‘ä»¬ä»ç„¶å¯ä»¥æ£€æŸ¥ pub_dateï¼Œä»¥ç¡®ä¿å®ƒä¸æ–‡ä»¶åä»£è¡¨çš„æ—¥æœŸä¸€è‡´
                    pub_date_str = item.get('pub_date')
                    if not pub_date_str:
                        continue # æ²¡æœ‰æ—¥æœŸçš„æ¡ç›®è·³è¿‡

                    # è§£æ pub_dateï¼Œç¡®è®¤å®ƒç¡®å®æ˜¯ç›®æ ‡æ—¥æœŸ
                    item_date = parse_pub_date(pub_date_str)
                    if item_date != target_date:
                        continue # pubDate ä¸æ–‡ä»¶æ—¥æœŸä¸åŒ¹é…ï¼Œè·³è¿‡

                    # 3. æå–æ‰€éœ€ä¿¡æ¯
                    search_term = item.get('title', 'N/A')
                    traffic_num = item.get('traffic_num', 0)
                    pub_date = item_date # ä½¿ç”¨è§£æåçš„æ—¥æœŸ
                    regions = item.get('regions', [])
                    # å¦‚æœJSONä¸­æ²¡æœ‰å›½å®¶ä¿¡æ¯ï¼Œåˆ™ä½¿ç”¨æ–‡ä»¶å¤¹åç§°ä½œä¸ºå›½å®¶
                    country = item.get('country', folder_country)
                    news_list = item.get('news', [])

                    if not news_list:
                         continue # å¦‚æœæ²¡æœ‰ news é¡¹ï¼Œåˆ™è·³è¿‡

                    # éå† news åˆ—è¡¨ï¼Œä¸ºæ¯ä¸ª news_item åˆ›å»ºä¸€è¡Œè®°å½•
                    for news_item in news_list:
                        news_title = news_item.get('title', 'N/A')
                        news_source = news_item.get('source', 'N/A')

                        # æ·»åŠ è¿™ä¸€è¡Œåˆ°ç»“æœåˆ—è¡¨
                        results_list.append({
                            "Search Term": search_term,
                            "News Title": news_title,
                            "News Source": news_source,
                            "Traffic Num": traffic_num,
                            "Pub Date": pub_date,
                            "Regions": regions, # å¯ä»¥ä¿ç•™æ•´ä¸ªåˆ—è¡¨
                            "Country": country # æ·»åŠ å›½å®¶ä¿¡æ¯
                        })

@st.cache_data

def load_data_by_date_range(start_date, end_date, _progress_callback=None):
    """æ ¹æ®æ—¥æœŸèŒƒå›´åŠ è½½æ•°æ®"""
    all_extracted_data_list = []
    current_date = start_date
    total_days = (end_date - start_date).days + 1
    current_day = 0
    
    while current_date <= end_date:
        # print(f"Attempting to load file for date: {current_date.strftime('%Y-%m-%d')}") # å¯é€‰ï¼šæ˜¾ç¤ºåŠ è½½è¿›åº¦
        load_and_process_file_for_date(current_date, all_extracted_data_list)
        current_date += timedelta(days=1)
        current_day += 1
        
        # è°ƒç”¨è¿›åº¦å›è°ƒå‡½æ•°
        if _progress_callback:
            progress = current_day / total_days
            _progress_callback(progress, f"æ­£åœ¨åŠ è½½ {current_date.strftime('%Y-%m-%d')} çš„æ•°æ®...")

    # æŒ‰å‘å¸ƒæ—¥æœŸï¼ˆé™åºï¼‰å’Œæµé‡æ•°ï¼ˆé™åºï¼‰æ’åº
    all_extracted_data_list.sort(key=lambda x: (x["Pub Date"], x["Traffic Num"]), reverse=True)
    return all_extracted_data_list

@st.cache_data

def estimate_tokens(text, model_name="gpt-4o"):
    """
    ä¼°ç®—æ–‡æœ¬çš„ token æ•°é‡
    """
    try:
        encoding = tiktoken.encoding_for_model(model_name)
    except KeyError:
        encoding = tiktoken.get_encoding("cl100k_base") # fallback
    num_tokens = len(encoding.encode(text))
    return num_tokens



def refresh_model_list(endpoint, api_key):
    """ä»æŒ‡å®šç«¯ç‚¹åˆ·æ–°æ¨¡å‹åˆ—è¡¨"""
    with st.status("æ­£åœ¨åˆ·æ–°æ¨¡å‹åˆ—è¡¨...", expanded=True) as status:
        try:
            st.write("ğŸ”„ å°è¯•ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯è·å–æ¨¡å‹åˆ—è¡¨...")
            # é¦–å…ˆå°è¯•ä½¿ç”¨ OpenAI å®¢æˆ·ç«¯è·å–æ¨¡å‹åˆ—è¡¨
            try:
                client = OpenAI(base_url=endpoint, api_key=api_key)
                models = client.models.list()
                model_options = [m.id for m in models.data]
                # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„æ¨¡å‹åˆ—è¡¨
                st.session_state['model_options'] = model_options
                status.update(label="æ¨¡å‹åˆ—è¡¨åˆ·æ–°æˆåŠŸ", state="complete", expanded=False)
                st.toast("âœ… æ¨¡å‹åˆ—è¡¨å·²æ›´æ–°ï¼", icon="ğŸ”„")
                return
            except Exception as e:
                # OpenAI å®¢æˆ·ç«¯å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨é€šç”¨ HTTP è¯·æ±‚
                st.write(f"âš ï¸ OpenAI å®¢æˆ·ç«¯æ–¹å¼å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ HTTP è¯·æ±‚: {e}")
            
            st.write("ğŸ”„ å°è¯•ä½¿ç”¨ HTTP è¯·æ±‚è·å–æ¨¡å‹åˆ—è¡¨...")
            # å°è¯•ä½¿ç”¨é€šç”¨ HTTP è¯·æ±‚è·å–æ¨¡å‹åˆ—è¡¨
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            # æ„å»ºæ¨¡å‹åˆ—è¡¨ç«¯ç‚¹ URL
            models_endpoint = endpoint
            if not models_endpoint.endswith('/v1/models'):
                if models_endpoint.endswith('/'):
                    models_endpoint += 'v1/models'
                else:
                    models_endpoint += '/v1/models'
            
            st.write(f"ğŸŒ è®¿é—®ç«¯ç‚¹: {models_endpoint}")
            response = requests.get(models_endpoint, headers=headers, timeout=10)
            response.raise_for_status()  # æ£€æŸ¥å“åº”çŠ¶æ€
            
            st.write("ğŸ“ è§£æå“åº”æ•°æ®...")
            # è§£æå“åº”
            data = response.json()
            # å°è¯•ä¸åŒçš„å“åº”æ ¼å¼
            if 'data' in data:
                # OpenAI æ ¼å¼
                model_options = [m['id'] for m in data['data']]
                st.write(f"âœ… æ‰¾åˆ° {len(model_options)} ä¸ªæ¨¡å‹")
            elif 'models' in data:
                # å…¶ä»–æ ¼å¼ï¼Œå‡è®¾ models å­—æ®µåŒ…å«æ¨¡å‹åˆ—è¡¨
                model_options = [m['id'] if 'id' in m else m['name'] for m in data['models']]
                st.write(f"âœ… æ‰¾åˆ° {len(model_options)} ä¸ªæ¨¡å‹")
            else:
                # å°è¯•ç›´æ¥æå–æ¨¡å‹ ID
                model_options = []
                status.update(label="è§£ææ¨¡å‹åˆ—è¡¨å¤±è´¥", state="error", expanded=True)
                st.error("æ— æ³•è§£ææ¨¡å‹åˆ—è¡¨å“åº”æ ¼å¼")
                return
            
            if model_options:
                # æ›´æ–°ä¼šè¯çŠ¶æ€ä¸­çš„æ¨¡å‹åˆ—è¡¨
                st.session_state['model_options'] = model_options
                status.update(label="æ¨¡å‹åˆ—è¡¨åˆ·æ–°æˆåŠŸ", state="complete", expanded=False)
                st.toast("âœ… æ¨¡å‹åˆ—è¡¨å·²æ›´æ–°ï¼", icon="ğŸ”„")
            else:
                status.update(label="æœªæ‰¾åˆ°æ¨¡å‹åˆ—è¡¨", state="error", expanded=True)
                st.error("æœªæ‰¾åˆ°æ¨¡å‹åˆ—è¡¨")
        except Exception as e:
            status.update(label="è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥", state="error", expanded=True)
            st.error(f"è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")

@st.cache_data

def generate_simple_markdown_table(df_filtered, max_rows=100000):
    """
    ç”Ÿæˆç®€åŒ–ç‰ˆçš„ markdown è¡¨æ ¼
    """
    if df_filtered.empty:
        return "No data to display."

    # é™åˆ¶è¡Œæ•°ä»¥å‡å°‘ token
    df_to_use = df_filtered.head(max_rows)

    # é‡å‘½ååˆ—ä»¥ç¬¦åˆè¦æ±‚
    df_simple = df_to_use.rename(columns={
        "æ ‡é¢˜": "news_title",
        "ä¿¡æº": "source",
        "æœç´¢è¯": "title",
        "æµé‡": "traffic_num",
        "å‘å¸ƒæ—¥æœŸ": "pub_date",
        "åœ°åŒº": "regions",
        "å›½å®¶": "country"
    })

    # è½¬æ¢æ—¥æœŸæ ¼å¼å’Œæµé‡æ ¼å¼
    df_simple["pub_date"] = df_simple["pub_date"].astype(str)
    df_simple["traffic_num"] = df_simple["traffic_num"].astype(int)

    # ç”Ÿæˆ markdown è¡¨æ ¼
    lines = []
    lines.append('')
    lines.append("news_title | source | title | traffic_num | pub_date | regions | country")
    lines.append("---|---|---|---|---|---|---")

    for _, row in df_simple.iterrows():
        line = f"{row['news_title']} | {row['source']} | {row['title']} | {row['traffic_num']} | {row['pub_date']} | {row['regions']} | {row['country']}"
        lines.append(line)

    return "\n".join(lines)


# --- Streamlit åº”ç”¨ ---
st.set_page_config(page_title="Global Trending Now çœ‹æ¿", layout="wide")

# é¡µé¢æ ‡é¢˜å’Œç®€ä»‹
header_container = st.container(border=True)
with header_container:
    st.title("ğŸ” Global Trending Now")
    st.markdown("### å…¨çƒçƒ­ç‚¹æœç´¢è¶‹åŠ¿åˆ†æå¹³å°")
    st.markdown("å®æ—¶è¿½è¸ªå…¨çƒå„å›½çƒ­ç‚¹æœç´¢è¶‹åŠ¿ï¼Œæä¾›æ•°æ®å¯è§†åŒ–å’ŒAIåˆ†æåŠŸèƒ½")

# åº”ç”¨åŠŸèƒ½ä»‹ç»
features_container = st.container(border=True)
with features_container:
    st.markdown("## ğŸ“‹ åŠŸèƒ½ç®€ä»‹")
    col_features1, col_features2, col_features3 = st.columns(3)
    with col_features1:
        st.subheader("ğŸ“Š æ•°æ®å¯è§†åŒ–")
        st.markdown("- å›½å®¶æ–°é—»æ•°é‡åˆ†å¸ƒ")
        st.markdown("- å›½å®¶å¹³å‡æµé‡å¯¹æ¯”")
        st.markdown("- æµé‡è¶‹åŠ¿åˆ†æ")
        st.markdown("- æ–°é—»æ¥æºåˆ†å¸ƒ")
    with col_features2:
        st.subheader("ğŸ”§ æ•°æ®ç­›é€‰")
        st.markdown("- æŒ‰å›½å®¶ç­›é€‰")
        st.markdown("- æŒ‰åœ°åŒºç­›é€‰")
        st.markdown("- æŒ‰æµé‡é˜ˆå€¼ç­›é€‰")
        st.markdown("- å¤šç»´åº¦ç»„åˆç­›é€‰")
    with col_features3:
        st.subheader("ğŸ¤– AI åˆ†æ")
        st.markdown("- çƒ­ç‚¹è¶‹åŠ¿æ™ºèƒ½åˆ†æ")
        st.markdown("- å¤šè¯­è¨€æ”¯æŒ")
        st.markdown("- å®æ—¶å¯¹è¯äº¤äº’")
        st.markdown("- æ·±åº¦æ´å¯Ÿç”Ÿæˆ")

# ä½¿ç”¨æŒ‡å—
guide_container = st.container(border=True)
with guide_container:
    st.markdown("## ğŸš€ ä½¿ç”¨æŒ‡å—")
    st.markdown("1. **é€‰æ‹©æ—¥æœŸèŒƒå›´**ï¼šåœ¨ä¸‹æ–¹é€‰æ‹©æ‚¨è¦åˆ†æçš„æ•°æ®æ—¶é—´èŒƒå›´ï¼ˆè¿‘3å¤©ã€7å¤©æˆ–30å¤©ï¼‰")
    st.markdown("2. **åº”ç”¨ç­›é€‰æ¡ä»¶**ï¼šæ ¹æ®éœ€è¦æŒ‰å›½å®¶ã€åœ°åŒºæˆ–æµé‡è¿›è¡Œæ•°æ®ç­›é€‰")
    st.markdown("3. **æŸ¥çœ‹æ•°æ®å¯è§†åŒ–**ï¼šæµè§ˆç”Ÿæˆçš„å„ç±»å›¾è¡¨ï¼Œäº†è§£å…¨çƒçƒ­ç‚¹è¶‹åŠ¿")
    st.markdown("4. **é…ç½®AIåˆ†æ**ï¼šåœ¨å³ä¾§è®¾ç½®AIæ¨¡å‹å’Œç«¯ç‚¹ï¼ˆå¦‚éœ€ä½¿ç”¨è‡ªå®šä¹‰ç«¯ç‚¹ï¼‰")
    st.markdown("5. **å¯åŠ¨AIåˆ†æ**ï¼šç‚¹å‡»'å¯åŠ¨AIåˆ†æ'æŒ‰é’®ï¼Œè·å–AIç”Ÿæˆçš„æ·±åº¦æ´å¯Ÿ")
    st.markdown("6. **ä¸AIå¯¹è¯**ï¼šæ ¹æ®åˆ†æç»“æœï¼Œç»§ç»­ä¸AIè¿›è¡Œæ·±å…¥è®¨è®º")

# åˆå§‹åŒ– session state æ¥å­˜å‚¨æ•°æ®
if 'data' not in st.session_state:
    st.session_state['data'] = []
if 'selected_date_range' not in st.session_state:
    st.session_state['selected_date_range'] = '7d' # é»˜è®¤ä¸ºè¿‘7å¤©
if 'df' not in st.session_state:
    st.session_state['df'] = None
if 'df_filtered' not in st.session_state:
    st.session_state['df_filtered'] = None
if 'ai_active' not in st.session_state:
    st.session_state['ai_active'] = False
if 'ai_messages' not in st.session_state:
    st.session_state['ai_messages'] = []
if 'token_count' not in st.session_state:
    st.session_state['token_count'] = 0
if 'ai_client' not in st.session_state:
    st.session_state['ai_client'] = None

# æ—¥æœŸèŒƒå›´é€‰æ‹©åŒºåŸŸ - æ›´çªå‡ºçš„ä½ç½®
st.markdown("## ğŸ“… é€‰æ‹©æ•°æ®æ—¥æœŸèŒƒå›´")
date_container = st.container(border=True)
with date_container:
    col1, col2, col3 = st.columns(3)
    with col1:
        if st.button("è¿‘ 3 å¤©", width='stretch', type="primary" if st.session_state.selected_date_range == '3d' else "secondary"):
            start_date = (datetime.now().date() - timedelta(days=3))
            end_date = datetime.now().date()
            total_days = (end_date - start_date).days + 1
            
            # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€å®¹å™¨
            with st.status(f"æ­£åœ¨åŠ è½½è¿‘3å¤©æ•°æ®...", expanded=True) as status:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def progress_callback(progress, message):
                    progress_bar.progress(progress)
                    status_text.text(message)
                
                st.session_state['data'] = load_data_by_date_range(start_date, end_date, progress_callback)
                st.session_state['selected_date_range'] = '3d'
                # é‡ç½® AI çŠ¶æ€
                st.session_state['ai_active'] = False
                st.session_state['ai_messages'] = []
                st.session_state['ai_client'] = None
                
                status.update(label="è¿‘3å¤©æ•°æ®åŠ è½½å®Œæˆ", state="complete", expanded=False)
                st.toast("âœ… è¿‘3å¤©æ•°æ®åŠ è½½å®Œæˆï¼", icon="ğŸ“Š")
                st.rerun()
    with col2:
        if st.button("è¿‘ 7 å¤©", width='stretch', type="primary" if st.session_state.selected_date_range == '7d' else "secondary"):
            start_date = (datetime.now().date() - timedelta(days=7))
            end_date = datetime.now().date()
            total_days = (end_date - start_date).days + 1
            
            # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€å®¹å™¨
            with st.status(f"æ­£åœ¨åŠ è½½è¿‘7å¤©æ•°æ®...", expanded=True) as status:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def progress_callback(progress, message):
                    progress_bar.progress(progress)
                    status_text.text(message)
                
                st.session_state['data'] = load_data_by_date_range(start_date, end_date, progress_callback)
                st.session_state['selected_date_range'] = '7d'
                # é‡ç½® AI çŠ¶æ€
                st.session_state['ai_active'] = False
                st.session_state['ai_messages'] = []
                st.session_state['ai_client'] = None
                
                status.update(label="è¿‘7å¤©æ•°æ®åŠ è½½å®Œæˆ", state="complete", expanded=False)
                st.toast("âœ… è¿‘7å¤©æ•°æ®åŠ è½½å®Œæˆï¼", icon="ğŸ“Š")
                st.rerun()
    with col3:
        if st.button("è¿‘ 30 å¤©", width='stretch', type="primary" if st.session_state.selected_date_range == '30d' else "secondary"):
            start_date = (datetime.now().date() - timedelta(days=30))
            end_date = datetime.now().date()
            total_days = (end_date - start_date).days + 1
            
            # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€å®¹å™¨
            with st.status(f"æ­£åœ¨åŠ è½½è¿‘30å¤©æ•°æ®...", expanded=True) as status:
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                def progress_callback(progress, message):
                    progress_bar.progress(progress)
                    status_text.text(message)
                
                st.session_state['data'] = load_data_by_date_range(start_date, end_date, progress_callback)
                st.session_state['selected_date_range'] = '30d'
                # é‡ç½® AI çŠ¶æ€
                st.session_state['ai_active'] = False
                st.session_state['ai_messages'] = []
                st.session_state['ai_client'] = None
                
                status.update(label="è¿‘30å¤©æ•°æ®åŠ è½½å®Œæˆ", state="complete", expanded=False)
                st.toast("âœ… è¿‘30å¤©æ•°æ®åŠ è½½å®Œæˆï¼", icon="ğŸ“Š")
                st.rerun()

# å¦‚æœ session state ä¸­æ²¡æœ‰æ•°æ®ï¼Œåˆ™åŠ è½½é»˜è®¤çš„è¿‘7å¤©æ•°æ®
if not st.session_state['data']:
    start_date = (datetime.now().date() - timedelta(days=7))
    end_date = datetime.now().date()
    
    # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€å®¹å™¨
    with st.status("æ­£åœ¨åŠ è½½é»˜è®¤æ•°æ®ï¼ˆè¿‘7å¤©ï¼‰...", expanded=True) as status:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def progress_callback(progress, message):
            progress_bar.progress(progress)
            status_text.text(message)
        
        st.session_state['data'] = load_data_by_date_range(start_date, end_date, progress_callback)
        st.session_state['selected_date_range'] = '7d'
        
        status.update(label="é»˜è®¤æ•°æ®åŠ è½½å®Œæˆ", state="complete", expanded=False)
        st.toast("âœ… é»˜è®¤æ•°æ®åŠ è½½å®Œæˆï¼", icon="ğŸ“Š")

# æ˜¾ç¤ºåŠ è½½çš„æ•°æ®
if st.session_state['data']:
    st.caption(f"æ•°æ®èŒƒå›´: {min(item['Pub Date'] for item in st.session_state['data'])} è‡³ {max(item['Pub Date'] for item in st.session_state['data'])}ï¼Œå…±æ‰¾åˆ° {len(st.session_state['data'])} æ¡ç›¸å…³æ–°é—»è®°å½•")
    st.caption(f"")

    # åˆ›å»º DataFrame ä»¥ä¾¿æ›´å¥½åœ°å±•ç¤º
    import pandas as pd
    df_data = []
    for item in st.session_state['data']:
        regions_list = item["Regions"]
        regions_str = "; ".join(regions_list)
        # å¤„ç†å›½å®¶ä¿¡æ¯ï¼Œå¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–é›†åˆ
        country_info = item["Country"]
        if isinstance(country_info, (set, list)):
            country_str = "; ".join(country_info)
        else:
            country_str = country_info if country_info else "æœªçŸ¥"
        df_data.append({
            "æœç´¢è¯": item["Search Term"],
            "æ ‡é¢˜": item["News Title"],
            "ä¿¡æº": item["News Source"],
            "æµé‡": item["Traffic Num"],
            "å‘å¸ƒæ—¥æœŸ": item["Pub Date"],
            "åœ°åŒº": regions_str,
            "åœ°åŒºæ•°é‡": len(regions_list),
            "å›½å®¶": country_str
        })

    df = pd.DataFrame(df_data)
    st.session_state['df'] = df

    # --- æ•°æ®æ¦‚è§ˆç»Ÿè®¡å¡ç‰‡ ---
    st.markdown("## ğŸ“Š æ•°æ®æ¦‚è§ˆ")
    stats_container = st.container(border=True)
    with stats_container:
        # ç¬¬ä¸€è¡Œç»Ÿè®¡å¡ç‰‡ï¼šæ ¸å¿ƒæŒ‡æ ‡
        col_stats1, col_stats2, col_stats3, col_stats4 = st.columns(4)
        
        with col_stats1:
            total_records = len(df)
            st.metric("æ€»æ–°é—»è®°å½•æ•°", f"{total_records:,}")
        
        with col_stats2:
            unique_countries = df["å›½å®¶"].nunique()
            st.metric("æ¶‰åŠå›½å®¶æ•°é‡", unique_countries)
        
        with col_stats3:
            avg_traffic = df["æµé‡"].mean()
            st.metric("å¹³å‡æµé‡", f"{int(avg_traffic):,}")
        
        with col_stats4:
            unique_sources = df["ä¿¡æº"].nunique()
            st.metric("æ–°é—»æ¥æºæ•°é‡", unique_sources)
        
        # ç¬¬äºŒè¡Œç»Ÿè®¡å¡ç‰‡ï¼šå›½å®¶ç›¸å…³æŒ‡æ ‡
        col_stats5, col_stats6, col_stats7, col_stats8 = st.columns(4)
        
        with col_stats5:
            # æµé‡æœ€é«˜çš„å›½å®¶
            top_traffic_country = df.groupby("å›½å®¶")["æµé‡"].sum().idxmax()
            top_traffic_value = df.groupby("å›½å®¶")["æµé‡"].sum().max()
            st.metric("æµé‡æœ€é«˜çš„å›½å®¶", top_traffic_country)
            st.caption(f"æ€»æµé‡: {int(top_traffic_value):,}")
        
        with col_stats6:
            # æ–°é—»è®°å½•æœ€å¤šçš„å›½å®¶
            top_news_country = df.groupby("å›½å®¶").size().idxmax()
            top_news_count = df.groupby("å›½å®¶").size().max()
            st.metric("æ–°é—»æœ€å¤šçš„å›½å®¶", top_news_country)
            st.caption(f"æ€»è®°å½•: {top_news_count:,}")
        
        with col_stats7:
            # å¹³å‡æ¯æ¡æ–°é—»çš„æµé‡
            avg_traffic_per_news = df["æµé‡"].sum() / len(df)
            st.metric("å¹³å‡æ¯æ¡æ–°é—»æµé‡", f"{int(avg_traffic_per_news):,}")
        
        with col_stats8:
            # ä¸åŒæœç´¢è¯çš„æ•°é‡
            unique_search_terms = df["æœç´¢è¯"].nunique()
            st.metric("ç‹¬ç‰¹æœç´¢è¯æ•°é‡", unique_search_terms)
    
    # --- ç­›é€‰åŠŸèƒ½ ---
    st.markdown("## ğŸ” æ•°æ®ç­›é€‰")
    
    # åˆ›å»ºç­›é€‰åŒºåŸŸçš„å®¹å™¨
    filter_container = st.container(border=True)
    
    with filter_container:
        st.markdown("### ç­›é€‰æ¡ä»¶")
        st.markdown("æ ¹æ®æ‚¨çš„éœ€æ±‚é€‰æ‹©ç­›é€‰æ¡ä»¶ï¼Œç³»ç»Ÿå°†å®æ—¶æ›´æ–°æ•°æ®å±•ç¤ºå’Œå¯è§†åŒ–ç»“æœ")
        
        # ç¬¬ä¸€è¡Œç­›é€‰æ¡ä»¶ï¼šä¸»è¦ç­›é€‰å™¨
        col_f1, col_f2, col_f3 = st.columns(3)
        with col_f1:
            # ä»å®é™…æ•°æ®ä¸­è·å–æ‰€æœ‰å›½å®¶åˆ—è¡¨
            all_countries = df["å›½å®¶"].unique().tolist()
            # ç¡®ä¿åˆ—è¡¨ä¸ä¸ºç©º
            if not all_countries:
                all_countries = []
            # æ·»åŠ "æ‰€æœ‰å›½å®¶"é€‰é¡¹åˆ°å¼€å¤´
            all_countries.insert(0, "æ‰€æœ‰å›½å®¶")
            country_filter = st.selectbox(
                "ğŸŒ æŒ‰å›½å®¶ç­›é€‰", 
                all_countries, 
                index=0, 
                key="country_filter",
                help="é€‰æ‹©ç‰¹å®šå›½å®¶æˆ–æŸ¥çœ‹æ‰€æœ‰å›½å®¶çš„æ•°æ®"
            )
        with col_f2:
            region_filter = st.text_input(
                "ğŸ“ æŒ‰åœ°åŒºç­›é€‰", 
                "", 
                key="region_filter", 
                placeholder="ä¾‹å¦‚: åŠ åˆ©ç¦å°¼äºšå·, çº½çº¦",
                help="æ”¯æŒå¤šä¸ªåœ°åŒºï¼Œç”¨é€—å·åˆ†éš”"
            )
        with col_f3:
            min_traffic_filter = st.number_input(
                "ğŸ“Š æœ€ä½æµé‡ç­›é€‰", 
                min_value=0, 
                value=0, 
                step=100, 
                key="min_traffic_filter",
                help="ç­›é€‰æµé‡å¤§äºç­‰äºæŒ‡å®šå€¼çš„æ•°æ®"
            )
        
        # æ·»åŠ æ¸…é™¤ç­›é€‰æŒ‰é’®å’Œç­›é€‰ä¿¡æ¯
        col_clear, col_info = st.columns([1, 3])
        with col_clear:
            if st.button("ğŸ—‘ï¸ æ¸…é™¤ç­›é€‰", type="secondary", width='stretch'):
                with st.spinner("æ­£åœ¨æ¸…é™¤ç­›é€‰æ¡ä»¶..."):
                    # é‡ç½®æ‰€æœ‰ç­›é€‰å™¨
                    st.session_state['country_filter'] = "æ‰€æœ‰å›½å®¶"
                    st.session_state['region_filter'] = ""
                    st.session_state['min_traffic_filter'] = 0
                    st.toast("âœ… ç­›é€‰æ¡ä»¶å·²æ¸…é™¤ï¼", icon="ğŸ—‘ï¸")
                    st.rerun()
        with col_info:
            active_filters = []
            if country_filter != "æ‰€æœ‰å›½å®¶":
                active_filters.append(f"å›½å®¶: {country_filter}")
            if region_filter:
                active_filters.append(f"åœ°åŒº: {region_filter}")
            if min_traffic_filter > 0:
                active_filters.append(f"æœ€ä½æµé‡: {min_traffic_filter}")
            
            if active_filters:
                st.info(f"å½“å‰æ¿€æ´»çš„ç­›é€‰æ¡ä»¶: {', '.join(active_filters)}")
            else:
                st.info("æœªåº”ç”¨ä»»ä½•ç­›é€‰æ¡ä»¶ï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®")

    with st.spinner("æ­£åœ¨åº”ç”¨ç­›é€‰æ¡ä»¶..."):
        df_current = df.copy()
        # å›½å®¶ç­›é€‰
        if country_filter != "æ‰€æœ‰å›½å®¶":
            df_current = df_current[df_current["å›½å®¶"] == country_filter]
        
        # åœ°åŒºç­›é€‰
        if region_filter:
            regions_to_filter = [r.strip() for r in region_filter.split(",") if r.strip()]
            mask = False
            for r in regions_to_filter:
                mask = mask | df_current["åœ°åŒº"].str.contains(r, case=False, na=False)
            df_current = df_current[mask]
        
        # æœ€ä½æµé‡ç­›é€‰
        if min_traffic_filter > 0:
            df_current = df_current[df_current["æµé‡"] >= min_traffic_filter]

        # æ£€æŸ¥æ˜¯å¦æœ‰ç­›é€‰æ¡ä»¶
        has_active_filters = (country_filter != "æ‰€æœ‰å›½å®¶") or region_filter or (min_traffic_filter > 0)
        
        st.session_state['df_filtered'] = df_current
        # æ˜¾ç¤ºç­›é€‰ç»“æœé€šçŸ¥
        if has_active_filters:
            st.toast(f"âœ… ç­›é€‰å®Œæˆï¼å…±æ‰¾åˆ° {len(df_current)} æ¡è®°å½•", icon="ğŸ”")
        else:
            st.toast("âœ… å·²æ˜¾ç¤ºæ‰€æœ‰æ•°æ®", icon="ğŸ“Š")
    
    # æ˜¾ç¤ºç­›é€‰ç»“æœç»Ÿè®¡
    filter_stats = []
    if country_filter != "æ‰€æœ‰å›½å®¶":
        filter_stats.append(f"å›½å®¶: {country_filter}")
    if region_filter:
        filter_stats.append(f"åœ°åŒº: {region_filter}")
    if min_traffic_filter > 0:
        filter_stats.append(f"æœ€ä½æµé‡: {min_traffic_filter}")
    
    if filter_stats:
        st.caption(f"å½“å‰ç­›é€‰æ¡ä»¶: {', '.join(filter_stats)} | å…± {len(df_current)} æ¡è®°å½•")
    else:
        st.caption(f"æœªåº”ç”¨ç­›é€‰æ¡ä»¶ | å…± {len(df_current)} æ¡è®°å½•")

    # --- å›½å®¶æ•°æ®å¯è§†åŒ–å›¾è¡¨ ---
    if not df_current.empty:
        st.markdown("## ğŸ“ˆ å›½å®¶æ•°æ®å¯è§†åŒ–")
        
        # åˆ›å»ºå›¾è¡¨å®¹å™¨
        chart_container = st.container(border=True)
        
        with chart_container:
            # è®¾ç½®å›¾è¡¨æ ·å¼ï¼Œç¡®ä¿è§†è§‰ä¸€è‡´æ€§
            sns.set_style("darkgrid")
            sns.set_palette("deep")
            sns.set_context("notebook", font_scale=1.0)
            
            # è®¾ç½®ç»Ÿä¸€çš„å›¾è¡¨é…ç½®
            plt.rcParams.update({
                'font.size': 12,
                'axes.titlesize': 14,
                'axes.labelsize': 12,
                'xtick.labelsize': 10,
                'ytick.labelsize': 10,
                'legend.fontsize': 10,
                'figure.figsize': (10, 6),
                'font.sans-serif': ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'WenQuanYi Micro Hei'],  # æ·»åŠ æ”¯æŒä¸­æ–‡çš„å­—ä½“
                'axes.unicode_minus': False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
            })
            
            # ç¬¬ä¸€è¡Œå›¾è¡¨ï¼šå›½å®¶æ–°é—»æ•°é‡å’Œå¹³å‡æµé‡
            st.markdown("### Country Core Metrics Comparison")
            col_chart1, col_chart2 = st.columns(2)
            
            with col_chart1:
                with st.spinner("æ­£åœ¨ç”Ÿæˆå›½å®¶æ–°é—»æ•°é‡å›¾è¡¨..."):
                    # æŒ‰å›½å®¶åˆ†ç»„ç»Ÿè®¡æ–°é—»æ•°é‡
                    country_news_count = df_current.groupby("å›½å®¶").size().reset_index(name="æ–°é—»æ•°é‡")
                    country_news_count = country_news_count.sort_values(by="æ–°é—»æ•°é‡", ascending=False).head(10)
                    
                    # åˆ›å»ºå›¾è¡¨
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.barplot(x="æ–°é—»æ•°é‡", y="å›½å®¶", data=country_news_count, hue="å›½å®¶", palette="viridis", ax=ax, legend=False)
                    ax.set_xlabel("Number of News Records")
                    ax.set_ylabel("å›½å®¶")
                    
                    # æ ¹æ®ç­›é€‰æ¡ä»¶è°ƒæ•´æ ‡é¢˜
                    if country_filter == "æ‰€æœ‰å›½å®¶":
                        ax.set_title("News Records by Country")
                    else:
                        ax.set_title(f"{country_filter} æ–°é—»è®°å½•æ•°é‡")
                    
                    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
                    for i, v in enumerate(country_news_count["æ–°é—»æ•°é‡"]):
                        ax.text(v + 0.5, i, str(v), va='center', fontsize=10)
                    
                    # è®¾ç½®å›¾è¡¨è¾¹è·
                    plt.tight_layout()
                    st.pyplot(fig)
            
            with col_chart2:
                with st.spinner("æ­£åœ¨ç”Ÿæˆå›½å®¶å¹³å‡æµé‡å›¾è¡¨..."):
                    # æŒ‰å›½å®¶åˆ†ç»„è®¡ç®—å¹³å‡æµé‡
                    country_avg_traffic = df_current.groupby("å›½å®¶")["æµé‡"].mean().reset_index(name="å¹³å‡æµé‡")
                    country_avg_traffic["å¹³å‡æµé‡"] = country_avg_traffic["å¹³å‡æµé‡"].astype(int)
                    country_avg_traffic = country_avg_traffic.sort_values(by="å¹³å‡æµé‡", ascending=False).head(10)
                    
                    # åˆ›å»ºå›¾è¡¨
                    fig, ax = plt.subplots(figsize=(10, 6))
                    sns.barplot(x="å¹³å‡æµé‡", y="å›½å®¶", data=country_avg_traffic, hue="å›½å®¶", palette="plasma", ax=ax, legend=False)
                    ax.set_xlabel("Average Traffic")
                    ax.set_ylabel("å›½å®¶")
                    
                    # æ ¹æ®ç­›é€‰æ¡ä»¶è°ƒæ•´æ ‡é¢˜
                    if country_filter == "æ‰€æœ‰å›½å®¶":
                        ax.set_title("Average Traffic by Country")
                    else:
                        ax.set_title(f"{country_filter} å¹³å‡æµé‡")
                    
                    # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
                    for i, v in enumerate(country_avg_traffic["å¹³å‡æµé‡"]):
                        ax.text(v + 0.5, i, f"{v:,}", va='center', fontsize=10)
                    
                    # è®¾ç½®å›¾è¡¨è¾¹è·
                    plt.tight_layout()
                    st.pyplot(fig)

            # ç¬¬äºŒè¡Œå›¾è¡¨ï¼šæµé‡è¶‹åŠ¿å’Œæ–°é—»æ¥æºåˆ†å¸ƒ
            st.markdown("### Traffic Trend and Source Analysis")
            col_chart3, col_chart4 = st.columns(2)
            
            with col_chart3:
                with st.spinner("æ­£åœ¨ç”Ÿæˆæµé‡è¶‹åŠ¿å›¾è¡¨..."):
                    # æŒ‰æ—¥æœŸçš„æµé‡è¶‹åŠ¿ï¼ˆå¦‚æœé€‰æ‹©äº†å•ä¸ªå›½å®¶æˆ–æ•°æ®é‡è¶³å¤Ÿï¼‰
                    if len(df_current) > 5:
                        # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—æ€»æµé‡
                        daily_traffic = df_current.groupby("å‘å¸ƒæ—¥æœŸ")["æµé‡"].sum().reset_index(name="æ€»æµé‡")
                        daily_traffic = daily_traffic.sort_values(by="å‘å¸ƒæ—¥æœŸ")
                        
                        # åˆ›å»ºå›¾è¡¨
                        fig, ax = plt.subplots(figsize=(10, 6))
                        sns.lineplot(x="å‘å¸ƒæ—¥æœŸ", y="æ€»æµé‡", data=daily_traffic, marker='o', ax=ax, color="#4C72B0")
                        ax.set_xlabel("Date")
                        ax.set_ylabel("Total Traffic")
                        
                        # æ ¹æ®ç­›é€‰æ¡ä»¶è°ƒæ•´æ ‡é¢˜
                        if country_filter == "æ‰€æœ‰å›½å®¶":
                            ax.set_title("Global Traffic Trend")
                        else:
                            ax.set_title(f"{country_filter} æµé‡è¶‹åŠ¿")
                        
                        # ä¼˜åŒ–æ—¥æœŸæ˜¾ç¤º
                        plt.xticks(rotation=45, fontsize=8)
                        plt.grid(True, alpha=0.3)
                        
                        # è®¾ç½®å›¾è¡¨è¾¹è·
                        plt.tight_layout()
                        st.pyplot(fig)
                    else:
                        st.info("æ•°æ®é‡ä¸è¶³ï¼Œæ— æ³•æ˜¾ç¤ºæµé‡è¶‹åŠ¿")
            
            with col_chart4:
                with st.spinner("æ­£åœ¨ç”Ÿæˆæ–°é—»æ¥æºåˆ†å¸ƒå›¾è¡¨..."):
                    # æ–°é—»æ¥æºåˆ†å¸ƒé¥¼å›¾
                    st.markdown("#### News Source Distribution")
                    source_distribution = df_current.groupby("ä¿¡æº").size().reset_index(name="æ•°é‡")
                    source_distribution = source_distribution.sort_values(by="æ•°é‡", ascending=False).head(8)
                    
                    # å¦‚æœæœ‰è¶…è¿‡8ä¸ªæ¥æºï¼Œå°†å‰©ä½™çš„åˆå¹¶ä¸º"å…¶ä»–"
                    if len(source_distribution) >= 8:
                        top_sources = source_distribution.head(7)
                        other_count = source_distribution.tail(len(source_distribution) - 7)["æ•°é‡"].sum()
                        if other_count > 0:
                            top_sources.loc[len(top_sources)] = ["å…¶ä»–", other_count]
                        source_distribution = top_sources
                    
                    # åˆ›å»ºé¥¼å›¾
                    fig, ax = plt.subplots(figsize=(10, 6))
                    ax.pie(source_distribution["æ•°é‡"], labels=source_distribution["ä¿¡æº"], autopct='%1.1f%%', startangle=90)
                    ax.axis('equal')  # ç¡®ä¿é¥¼å›¾æ˜¯åœ†å½¢
                    
                    # æ ¹æ®ç­›é€‰æ¡ä»¶è°ƒæ•´æ ‡é¢˜
                    if country_filter == "æ‰€æœ‰å›½å®¶":
                        ax.set_title("Global News Source Distribution")
                    else:
                        ax.set_title(f"{country_filter} æ–°é—»æ¥æºåˆ†å¸ƒ")
                    
                    # è®¾ç½®å›¾è¡¨è¾¹è·
                    plt.tight_layout()
                    st.pyplot(fig)
            
            # ç¬¬ä¸‰è¡Œå›¾è¡¨ï¼šæµé‡åˆ†å¸ƒå’Œåœ°åŒºåˆ†å¸ƒ
            st.markdown("### Traffic and Regional Distribution Analysis")
            col_chart5, col_chart6 = st.columns(2)
            
            with col_chart5:
                with st.spinner("æ­£åœ¨ç”Ÿæˆæµé‡åˆ†å¸ƒå›¾è¡¨..."):
                    # æµé‡åˆ†å¸ƒç®±çº¿å›¾
                    st.markdown("#### Traffic Distribution")
                    if country_filter == "æ‰€æœ‰å›½å®¶":
                        # å¤šå›½å®¶æµé‡åˆ†å¸ƒå¯¹æ¯”
                        if len(df_current["å›½å®¶"].unique()) > 1:
                            fig, ax = plt.subplots(figsize=(10, 6))
                            sns.boxplot(x="å›½å®¶", y="æµé‡", data=df_current, ax=ax, palette="Set3")
                            ax.set_xlabel("å›½å®¶")
                            ax.set_ylabel("Traffic")
                            ax.set_title("Traffic Distribution by Country")
                            plt.xticks(rotation=45, fontsize=8)
                            plt.tight_layout()
                            st.pyplot(fig)
                        else:
                            # å•ä¸ªå›½å®¶æµé‡åˆ†å¸ƒ
                            fig, ax = plt.subplots(figsize=(10, 6))
                            sns.boxplot(y="æµé‡", data=df_current, ax=ax, palette="Set3")
                            ax.set_ylabel("Traffic")
                            ax.set_title(f"{country_filter} æµé‡åˆ†å¸ƒ")
                            plt.tight_layout()
                            st.pyplot(fig)
                    else:
                        # å•ä¸ªå›½å®¶ä¸åŒåœ°åŒºçš„æµé‡åˆ†å¸ƒ
                        if "åœ°åŒº" in df_current.columns and len(df_current["åœ°åŒº"].unique()) > 1:
                            fig, ax = plt.subplots(figsize=(10, 6))
                            # åªæ˜¾ç¤ºæµé‡æœ€å¤§çš„å‰10ä¸ªåœ°åŒº
                            top_regions = df_current.groupby("åœ°åŒº")["æµé‡"].sum().nlargest(10).index
                            df_top_regions = df_current[df_current["åœ°åŒº"].isin(top_regions)]
                            sns.boxplot(x="åœ°åŒº", y="æµé‡", data=df_top_regions, ax=ax, palette="Set3")
                            ax.set_xlabel("Region")
                            ax.set_ylabel("Traffic")
                            ax.set_title(f"{country_filter} å„åœ°åŒºæµé‡åˆ†å¸ƒ")
                            plt.xticks(rotation=45, fontsize=8)
                            plt.tight_layout()
                            st.pyplot(fig)
                        else:
                            # å•ä¸ªå›½å®¶æµé‡åˆ†å¸ƒï¼ˆæ— åœ°åŒºæ•°æ®æˆ–åœ°åŒºæ•°æ®ä¸è¶³ï¼‰
                            fig, ax = plt.subplots(figsize=(10, 6))
                            sns.boxplot(y="æµé‡", data=df_current, ax=ax, palette="Set3")
                            ax.set_ylabel("æµé‡")
                            ax.set_title(f"{country_filter} æµé‡åˆ†å¸ƒ")
                            plt.tight_layout()
                            st.pyplot(fig)
            
            with col_chart6:
                with st.spinner("æ­£åœ¨ç”Ÿæˆåœ°åŒºåˆ†å¸ƒå›¾è¡¨..."):
                    # å›½å®¶åœ°åŒºåˆ†å¸ƒï¼ˆä»…å½“é€‰æ‹©å•ä¸ªå›½å®¶æ—¶ï¼‰
                    if country_filter != "æ‰€æœ‰å›½å®¶" and len(df_current) > 0:
                        # æŒ‰åœ°åŒºåˆ†ç»„ç»Ÿè®¡æ–°é—»æ•°é‡
                        region_news_count = df_current.groupby("åœ°åŒº").size().reset_index(name="æ–°é—»æ•°é‡")
                        region_news_count = region_news_count.sort_values(by="æ–°é—»æ•°é‡", ascending=False).head(10)
                        
                        # åˆ›å»ºå›¾è¡¨
                        fig, ax = plt.subplots(figsize=(10, 6))
                        sns.barplot(x="æ–°é—»æ•°é‡", y="åœ°åŒº", data=region_news_count, hue="åœ°åŒº", palette="RdBu_r", ax=ax, legend=False)
                        ax.set_xlabel("Number of News Records")
                        ax.set_ylabel("Region")
                        ax.set_title(f"News Records by Region")
                        
                        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
                        for i, v in enumerate(region_news_count["æ–°é—»æ•°é‡"]):
                            ax.text(v + 0.5, i, str(v), va='center', fontsize=10)
                        
                        # è®¾ç½®å›¾è¡¨è¾¹è·
                        plt.tight_layout()
                        st.pyplot(fig)
                    else:
                        # å½“é€‰æ‹©æ‰€æœ‰å›½å®¶æ—¶ï¼Œæ˜¾ç¤ºåœ°åŒºæ•°é‡åˆ†å¸ƒ
                        region_count = df_current.groupby("å›½å®¶")["åœ°åŒºæ•°é‡"].mean().reset_index(name="å¹³å‡åœ°åŒºæ•°é‡")
                        region_count = region_count.sort_values(by="å¹³å‡åœ°åŒºæ•°é‡", ascending=False).head(10)
                        
                        fig, ax = plt.subplots(figsize=(10, 6))
                        sns.barplot(x="å¹³å‡åœ°åŒºæ•°é‡", y="å›½å®¶", data=region_count, hue="å›½å®¶", palette="Purples", ax=ax, legend=False)
                        ax.set_xlabel("Average Number of Regions")
                        ax.set_ylabel("å›½å®¶")
                        ax.set_title("Average Regions Involved by Country")
                        
                        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
                        for i, v in enumerate(region_count["å¹³å‡åœ°åŒºæ•°é‡"]):
                            ax.text(v + 0.05, i, f"{v:.1f}", va='center', fontsize=10)
                        
                        # è®¾ç½®å›¾è¡¨è¾¹è·
                        plt.tight_layout()
                        st.pyplot(fig)
            
            # é‡ç½®Matplotlibè®¾ç½®ï¼Œé¿å…å½±å“åç»­å›¾è¡¨
            plt.close('all')
            sns.reset_orig()
    else:
        st.info("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ²¡æœ‰æ•°æ®å¯ç”¨äºå¯è§†åŒ–")

    # --- å§‹ç»ˆæ˜¾ç¤ºåŸå§‹è¡¨æ ¼ï¼ˆå¯æ’åºï¼‰---
    st.subheader("ğŸ“Š æ•°æ®è¡¨æ ¼")
    if region_filter or min_traffic_filter > 0:
        st.caption(f"ç­›é€‰ç»“æœ: å…± {len(df_current)} æ¡è®°å½•")
    else:
        st.caption(f"å…± {len(df)} æ¡è®°å½•")
    
    # è°ƒæ•´åˆ—é¡ºåºï¼Œå°†å›½å®¶å’Œåœ°åŒºåˆ—æ”¾åœ¨å‰é¢
    columns = [
        "å›½å®¶", "åœ°åŒº", "æœç´¢è¯", "æ ‡é¢˜", "ä¿¡æº", "æµé‡", "å‘å¸ƒæ—¥æœŸ", "åœ°åŒºæ•°é‡"
    ]
    
    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
    available_columns = [col for col in columns if col in df_current.columns]
    
    # æ˜¾ç¤ºè°ƒæ•´åçš„è¡¨æ ¼
    st.dataframe(
        df_current[available_columns], 
        width='stretch', 
        height=600,  # å›ºå®šé«˜åº¦é¿å…é¡µé¢å¤ªé•¿
        column_config={
            "å›½å®¶": st.column_config.Column(
                "å›½å®¶",
                width="medium",
                help="æ–°é—»æ¥æºå›½å®¶"
            ),
            "åœ°åŒº": st.column_config.Column(
                "åœ°åŒº",
                width="wide",
                help="æ–°é—»æ¥æºåœ°åŒº"
            ),
            "æœç´¢è¯": st.column_config.Column(
                "æœç´¢è¯",
                width="medium",
                help="çƒ­ç‚¹æœç´¢è¯"
            ),
            "æ ‡é¢˜": st.column_config.Column(
                "æ–°é—»æ ‡é¢˜",
                width="large",
                help="æ–°é—»æ ‡é¢˜"
            ),
            "ä¿¡æº": st.column_config.Column(
                "æ–°é—»æ¥æº",
                width="medium",
                help="æ–°é—»å‘å¸ƒæ¥æº"
            ),
            "æµé‡": st.column_config.NumberColumn(
                "æµé‡",
                width="small",
                help="æ–°é—»æµé‡æ•°å€¼",
                format="%d"
            ),
            "å‘å¸ƒæ—¥æœŸ": st.column_config.DateColumn(
                "å‘å¸ƒæ—¥æœŸ",
                width="small",
                help="æ–°é—»å‘å¸ƒæ—¥æœŸ"
            ),
            "åœ°åŒºæ•°é‡": st.column_config.NumberColumn(
                "æ¶‰åŠåœ°åŒºæ•°é‡",
                width="small",
                help="è¯¥æ–°é—»æ¶‰åŠçš„åœ°åŒºæ•°é‡"
            )
        }
    )

    # --- AI åŠŸèƒ½åŒºåŸŸ ---
    if st.session_state['data']:  # ä»…å½“æœ‰æ•°æ®æ—¶æ‰æ˜¾ç¤º AI åŠŸèƒ½
        st.subheader("ğŸ¤– AI åˆ†æåŠŸèƒ½")

        # AI é…ç½®è®¾ç½®
        with st.expander("âš™ï¸ AI é…ç½®", expanded=True):
            # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€ä¸­çš„ AI é…ç½®
            if 'ai_config' not in st.session_state:
                st.session_state['ai_config'] = {
                    'api_key': DEFAULT_API_KEY,
                    'endpoint': DEFAULT_ENDPOINT,
                    'model': DEFAULT_MODEL,
                    'supplier': DEFAULT_SUPPLIER
                }
            if 'model_options' not in st.session_state:
                st.session_state['model_options'] = get_provider_default_models(DEFAULT_SUPPLIER)
            
            # æ¨¡å‹ä¾›åº”å•†é€‰æ‹©
            provider_names = get_provider_names()
            model_supplier = st.selectbox(
                "æ¨¡å‹ä¾›åº”å•†", 
                provider_names, 
                index=provider_names.index(st.session_state['ai_config'].get('supplier', DEFAULT_SUPPLIER)),
                key="model_supplier"
            )
            
            # å½“ä¾›åº”å•†å˜åŒ–æ—¶æ›´æ–°é…ç½®å¹¶è‡ªåŠ¨è·å–æ¨¡å‹åˆ—è¡¨
            if model_supplier != st.session_state['ai_config'].get('supplier'):
                st.session_state['ai_config']['supplier'] = model_supplier
                # æ ¹æ®ä¾›åº”å•†è®¾ç½®é»˜è®¤ç«¯ç‚¹
                default_endpoint = get_provider_default_endpoint(model_supplier)
                st.session_state['ai_config']['endpoint'] = default_endpoint
                # è®¾ç½®é»˜è®¤æ¨¡å‹åˆ—è¡¨
                default_models = get_provider_default_models(model_supplier)
                st.session_state['model_options'] = default_models
                # å¦‚æœæœ‰é»˜è®¤æ¨¡å‹ï¼Œè®¾ç½®ç¬¬ä¸€ä¸ªä¸ºå½“å‰æ¨¡å‹
                if default_models:
                    st.session_state['ai_config']['model'] = default_models[0]
                # è‡ªåŠ¨åˆ·æ–°æ¨¡å‹åˆ—è¡¨
                if model_supplier != "Custom" and st.session_state['ai_config'].get('api_key'):
                    refresh_model_list(st.session_state['ai_config']['endpoint'], st.session_state['ai_config']['api_key'])
            
            # ç«¯ç‚¹è§„èŒƒåŒ–å‡½æ•°
            def normalize_endpoint(endpoint):
                """è§„èŒƒåŒ–ç«¯ç‚¹URLï¼Œç¡®ä¿ç¬¦åˆæ ‡å‡†æ ¼å¼"""
                if not endpoint:
                    return endpoint
                
                # æ·»åŠ åè®®ï¼ˆå¦‚æœç¼ºå°‘ï¼‰
                if not endpoint.startswith('http://') and not endpoint.startswith('https://'):
                    endpoint = 'https://' + endpoint
                
                # ç§»é™¤å°¾éƒ¨æ–œæ 
                endpoint = endpoint.rstrip('/')
                
                # ç¡®ä¿ä»¥ /v1 ç»“å°¾
                if not endpoint.endswith('/v1'):
                    endpoint += '/v1'
                
                return endpoint
            
            # æ ¹æ®ä¾›åº”å•†æ˜¾ç¤ºä¸åŒçš„é…ç½®é€‰é¡¹
            if model_supplier == "Custom":
                # è‡ªå®šä¹‰ä¾›åº”å•†æ˜¾ç¤ºç«¯ç‚¹è¾“å…¥
                ai_endpoint = st.text_input(
                    "è‡ªå®šä¹‰ç«¯ç‚¹", 
                    value=st.session_state['ai_config'].get('endpoint', DEFAULT_ENDPOINT), 
                    key="ai_endpoint"
                )
                if ai_endpoint != st.session_state['ai_config'].get('endpoint'):
                    # è§„èŒƒåŒ–ç«¯ç‚¹
                    normalized_endpoint = normalize_endpoint(ai_endpoint)
                    st.session_state['ai_config']['endpoint'] = normalized_endpoint
                    # æ˜¾ç¤ºè§„èŒƒåŒ–åçš„ç«¯ç‚¹
                    st.info(f"è§„èŒƒåŒ–åçš„ç«¯ç‚¹: {normalized_endpoint}")
            else:
                # é»˜è®¤ä¾›åº”å•†éšè—è‡ªå®šä¹‰ç«¯ç‚¹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„é»˜è®¤ç«¯ç‚¹
                default_endpoint = get_provider_default_endpoint(model_supplier)
                st.session_state['ai_config']['endpoint'] = default_endpoint
                # æ˜¾ç¤ºå½“å‰ç«¯ç‚¹ä¿¡æ¯
                st.info(f"å½“å‰ç«¯ç‚¹: {default_endpoint}")
            
            # API Key è¾“å…¥
            ai_api_key = st.text_input(
                "API Key", 
                type="password", 
                value=st.session_state['ai_config'].get('api_key', DEFAULT_API_KEY), 
                key="ai_api_key"
            )
            if ai_api_key != st.session_state['ai_config'].get('api_key'):
                st.session_state['ai_config']['api_key'] = ai_api_key
                # å½“ API Key å˜åŒ–æ—¶ï¼Œå¦‚æœä¸æ˜¯è‡ªå®šä¹‰ä¾›åº”å•†ï¼Œè‡ªåŠ¨åˆ·æ–°æ¨¡å‹åˆ—è¡¨
                if model_supplier != "Custom":
                    refresh_model_list(st.session_state['ai_config']['endpoint'], ai_api_key)
            
            # æ¨¡å‹é€‰æ‹©å’Œåˆ·æ–°
            col_model, col_refresh = st.columns([3, 1])
            with col_model:
                # è·å–æ¨¡å‹åˆ—è¡¨
                model_options = st.session_state.get('model_options', get_provider_default_models(model_supplier))
                # ç¡®ä¿æ¨¡å‹é€‰é¡¹ä¸ä¸ºç©º
                if not model_options:
                    model_options = ["è¯·å…ˆåˆ·æ–°æ¨¡å‹åˆ—è¡¨"]
                # ç¡®ä¿å½“å‰æ¨¡å‹åœ¨é€‰é¡¹åˆ—è¡¨ä¸­
                current_model = st.session_state['ai_config'].get('model')
                if current_model and current_model not in model_options:
                    model_options.insert(0, current_model)
                ai_model = st.selectbox(
                    "é€‰æ‹©æ¨¡å‹", 
                    model_options,
                    index=model_options.index(current_model) if current_model in model_options else 0,
                    key="ai_model"
                )
                if ai_model != current_model:
                    st.session_state['ai_config']['model'] = ai_model
            with col_refresh:
                st.markdown(" ")  # è°ƒæ•´å‚ç›´å¯¹é½
                if st.button("ğŸ”„ åˆ·æ–°æ¨¡å‹", key="refresh_models"):
                    current_endpoint = st.session_state['ai_config']['endpoint']
                    current_api_key = st.session_state['ai_config']['api_key']
                    refresh_model_list(current_endpoint, current_api_key)
        
        # æ¨¡å‹æµ‹è¯•æŒ‰é’®
        if st.button("ğŸ§ª æµ‹è¯•æ¨¡å‹è¿é€šæ€§", key="test_model"):
            test_endpoint = st.session_state['ai_config']['endpoint']
            test_api_key = st.session_state['ai_config']['api_key']
            test_model = st.session_state['ai_config']['model']
            
            if not test_api_key.strip():
                st.error("è¯·å…ˆå¡«å†™ API Key")
            else:
                with st.status("æ­£åœ¨æµ‹è¯•æ¨¡å‹è¿é€šæ€§...", expanded=True) as status:
                    try:
                        st.write(f"ğŸŒ æµ‹è¯•ç«¯ç‚¹: {test_endpoint}")
                        st.write(f"ğŸ¤– æµ‹è¯•æ¨¡å‹: {test_model}")
                        
                        # åˆ›å»ºä¸´æ—¶å®¢æˆ·ç«¯
                        st.write("ğŸ”§ åˆ›å»ºæµ‹è¯•å®¢æˆ·ç«¯...")
                        test_client = OpenAI(base_url=test_endpoint, api_key=test_api_key)
                        
                        # å‘é€æµ‹è¯•æ¶ˆæ¯
                        st.write("ğŸ“ å‡†å¤‡æµ‹è¯•æ¶ˆæ¯...")
                        test_messages = [
                            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæµ‹è¯•åŠ©æ‰‹ï¼Œåªéœ€è¦å›å¤'æµ‹è¯•æˆåŠŸï¼'å³å¯"},
                            {"role": "user", "content": "æµ‹è¯•æ¶ˆæ¯ï¼šè¯·å›å¤'æµ‹è¯•æˆåŠŸï¼'"}
                        ]
                        
                        # è°ƒç”¨æ¨¡å‹
                        st.write("ğŸš€ è°ƒç”¨æ¨¡å‹ API...")
                        response = test_client.chat.completions.create(
                            model=test_model,
                            messages=test_messages,
                            stream=False
                        )
                        
                        # æ£€æŸ¥å“åº”ç±»å‹
                        st.write("ğŸ“Š åˆ†ææ¨¡å‹å“åº”...")
                        if isinstance(response, str):
                            st.write(f"âš ï¸ æ¨¡å‹è¿”å›å­—ç¬¦ä¸²æ ¼å¼: {response}")
                            status.update(label="æ¨¡å‹æµ‹è¯•æˆåŠŸ", state="complete", expanded=False)
                            st.toast("âœ… æ¨¡å‹è¿æ¥æˆåŠŸï¼", icon="ğŸ§ª")
                        else:
                            # è·å–å›å¤å†…å®¹
                            if hasattr(response, 'choices') and len(response.choices) > 0:
                                if hasattr(response.choices[0], 'message') and hasattr(response.choices[0].message, 'content'):
                                    test_response = response.choices[0].message.content
                                    if test_response:
                                        st.write(f"âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸï¼")
                                        st.write(f"å›å¤å†…å®¹ï¼š{test_response}")
                                        status.update(label="æ¨¡å‹æµ‹è¯•æˆåŠŸ", state="complete", expanded=False)
                                        st.toast("âœ… æ¨¡å‹æµ‹è¯•æˆåŠŸï¼", icon="ğŸ§ª")
                                    else:
                                        st.write("âš ï¸ æ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œä½†æœªè¿”å›å†…å®¹")
                                        status.update(label="æ¨¡å‹æµ‹è¯•æˆåŠŸ", state="complete", expanded=False)
                                        st.toast("âš ï¸ æ¨¡å‹æµ‹è¯•æˆåŠŸï¼Œä½†æœªè¿”å›å†…å®¹", icon="ğŸ§ª")
                                else:
                                    st.write("âœ… æ¨¡å‹è¿æ¥æˆåŠŸï¼")
                                    st.write(f"å“åº”ç»“æ„: {response}")
                                    status.update(label="æ¨¡å‹æµ‹è¯•æˆåŠŸ", state="complete", expanded=False)
                                    st.toast("âœ… æ¨¡å‹è¿æ¥æˆåŠŸï¼", icon="ğŸ§ª")
                            else:
                                st.write("âœ… æ¨¡å‹è¿æ¥æˆåŠŸï¼")
                                st.write(f"å“åº”ç»“æ„: {response}")
                                status.update(label="æ¨¡å‹æµ‹è¯•æˆåŠŸ", state="complete", expanded=False)
                                st.toast("âœ… æ¨¡å‹è¿æ¥æˆåŠŸï¼", icon="ğŸ§ª")
                    except Exception as e:
                        status.update(label="æ¨¡å‹æµ‹è¯•å¤±è´¥", state="error", expanded=True)
                        st.error(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
                        # æ·»åŠ æ›´å¤šè°ƒè¯•ä¿¡æ¯
                        st.info(f"æµ‹è¯•é…ç½®ï¼š\nç«¯ç‚¹: {test_endpoint}\næ¨¡å‹: {test_model}")
                        st.toast("âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥", icon="âš ï¸")
        
        # ä½¿ç”¨ä¼šè¯çŠ¶æ€ä¸­çš„é…ç½®
        ai_endpoint = st.session_state['ai_config'].get('endpoint', DEFAULT_ENDPOINT)
        ai_api_key = st.session_state['ai_config'].get('api_key', DEFAULT_API_KEY)
        ai_model = st.session_state['ai_config'].get('model', DEFAULT_MODEL)

        if df_current.empty:
                st.error("å½“å‰ç­›é€‰æ¡ä»¶ä¸‹æ— æ•°æ®å¯ä¾›åˆ†æ")
        elif not ai_api_key.strip():
            st.error("è¯·å…ˆå¡«å†™ API Key")
        else:
            # ç”Ÿæˆç®€åŒ–è¡¨æ ¼ï¼ˆç”¨äºå‘é€ç»™ AIï¼‰
            markdown_table = generate_simple_markdown_table(df_current)
            # st.write("```" +markdown_table+ "```")
            # æ‹¼æ¥å‘é€ç»™ AI çš„å†…å®¹
            user_prompt_with_table = DEFAULT_USER_PROMPT + "\n\n" + markdown_table
            # user_prompt_with_table = "just for test you googit "  # æµ‹è¯•ç”¨
            # ä¼°ç®— Token
            with st.spinner("æ­£åœ¨ä¼°ç®— Token æ•°é‡..."):
                try:
                    system_tokens = estimate_tokens(DEFAULT_SYSTEM_PROMPT, ai_model)
                    user_tokens = estimate_tokens(user_prompt_with_table, ai_model)
                    total_tokens = system_tokens + user_tokens
                except Exception as e:
                    st.warning(f"Token ä¼°ç®—å¤±è´¥ï¼ˆä½¿ç”¨é»˜è®¤æ¨¡å‹ä¼°ç®—ï¼‰: {e}")
                    # fallback
                    total_tokens = estimate_tokens(
                        DEFAULT_SYSTEM_PROMPT + "\n\n" + user_prompt_with_table, 
                        "gpt-4o"
                    )
                # æ˜¾ç¤º Token ä¿¡æ¯ï¼ˆæŒä¹…æ˜¾ç¤ºï¼‰
                st.session_state['token_count'] = total_tokens
                
                # ä½¿ç”¨æ›´å‹å¥½çš„æ˜¾ç¤ºæ–¹å¼
                token_info_container = st.container(border=True)
                with token_info_container:
                    st.markdown("### ğŸ“Š Token ä¼°ç®—ä¿¡æ¯")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.metric("ç³»ç»Ÿæç¤ºè¯", f"{system_tokens:,}")
                    with col2:
                        st.metric("ç”¨æˆ·è¾“å…¥", f"{user_tokens:,}")
                    with col3:
                        st.metric("æ€»è®¡", f"{total_tokens:,}")
                    
                    # æ˜¾ç¤º Token ä½¿ç”¨æƒ…å†µçš„è¿›åº¦æ¡
                    max_tokens = DEFAULT_MAX_TOKENS
                    progress = min(total_tokens / max_tokens, 1.0)
                    st.progress(progress)
                    
                    if total_tokens > max_tokens:
                        st.error(f"âš ï¸ è¶…è¿‡ {max_tokens:,} tokens é™åˆ¶ï¼å¯èƒ½å½±å“åˆ†ææ•ˆæœã€‚")
                    else:
                        remaining = max_tokens - total_tokens
                        st.success(f"âœ… å‰©ä½™ Token: {remaining:,}")

                
        # å¯åŠ¨åˆ†ææŒ‰é’®
        if st.button("ğŸš€ å¯åŠ¨ AI åˆ†æ", type="primary"):
            if total_tokens > DEFAULT_MAX_TOKENS:
                st.warning(f"âš ï¸ è¶…è¿‡ {DEFAULT_MAX_TOKENS} tokens é™åˆ¶ï¼å¯èƒ½å½±å“åˆ†ææ•ˆæœã€‚")
                if st.button("â— ç¡®è®¤ç»§ç»­åˆ†æ", type="secondary", key="confirm_overlimit"):
                    with st.status("æ­£åœ¨å¯åŠ¨ AI åˆ†æ...", expanded=True) as status:
                        try:
                            st.write("ğŸ”§ åˆå§‹åŒ– AI å®¢æˆ·ç«¯...")
                            client = OpenAI(base_url=ai_endpoint, api_key=ai_api_key)
                            st.session_state['ai_client'] = client
                            
                            st.write("ğŸ“ å‡†å¤‡åˆ†ææ•°æ®...")
                            # å‘é€ç»™ AI çš„æ¶ˆæ¯
                            st.session_state['ai_messages'] = [
                                {"role": "system", "content": DEFAULT_SYSTEM_PROMPT},
                                {"role": "user", "content": user_prompt_with_table} # åŒ…å«è¡¨æ ¼
                            ]
                            
                            st.write("ğŸš€ å¯åŠ¨åˆ†ææµç¨‹...")
                            st.session_state['ai_active'] = True
                            
                            status.update(label="AI åˆ†æå·²å¯åŠ¨", state="complete", expanded=False)
                            st.toast("âœ… AI åˆ†æå·²å¯åŠ¨ï¼", icon="ğŸš€")
                            st.rerun()
                        except Exception as e:
                            status.update(label="AI åˆ†æå¯åŠ¨å¤±è´¥", state="error", expanded=True)
                            st.error(f"åˆå§‹åŒ– AI å®¢æˆ·ç«¯å¤±è´¥: {e}")
                            st.toast("âŒ AI åˆ†æå¯åŠ¨å¤±è´¥", icon="âš ï¸")
            else:
                # æœªè¶…é™ï¼Œç›´æ¥å¯åŠ¨
                with st.status("æ­£åœ¨å¯åŠ¨ AI åˆ†æ...", expanded=True) as status:
                    try:
                        st.write("ğŸ”§ åˆå§‹åŒ– AI å®¢æˆ·ç«¯...")
                        client = OpenAI(base_url=ai_endpoint, api_key=ai_api_key)
                        st.session_state['ai_client'] = client
                        
                        st.write("ğŸ“ å‡†å¤‡åˆ†ææ•°æ®...")
                        # å‘é€ç»™ AI çš„æ¶ˆæ¯
                        st.session_state['ai_messages'] = [
                            {"role": "system", "content": DEFAULT_SYSTEM_PROMPT},
                            {"role": "user", "content": user_prompt_with_table} # åŒ…å«è¡¨æ ¼
                        ]
                        
                        st.write("ğŸš€ å¯åŠ¨åˆ†ææµç¨‹...")
                        st.session_state['ai_active'] = True
                        
                        status.update(label="AI åˆ†æå·²å¯åŠ¨", state="complete", expanded=False)
                        st.toast("âœ… AI åˆ†æå·²å¯åŠ¨ï¼", icon="ğŸš€")
                        st.rerun()
                    except Exception as e:
                        status.update(label="AI åˆ†æå¯åŠ¨å¤±è´¥", state="error", expanded=True)
                        st.error(f"åˆå§‹åŒ– AI å®¢æˆ·ç«¯å¤±è´¥: {e}")
                        st.toast("âŒ AI åˆ†æå¯åŠ¨å¤±è´¥", icon="âš ï¸")

        # --- AI å¯¹è¯åŒºåŸŸ ---
        if st.session_state.get('ai_active', False) and st.session_state.get('ai_client', None):
            # æ‰‹åŠ¨æ·»åŠ ä¸€ç‚¹é—´è·
            st.divider()
            st.subheader("ğŸ’¬ AI å¯¹è¯")

            # æ˜¾ç¤ºå·²æœ‰å®Œæ•´å¯¹è¯
            messages = st.session_state.get('ai_messages', [])
            print(f"DEBUG: æ¶ˆæ¯å†å²é•¿åº¦: {len(messages)}")
            
            for msg in messages:
                if msg["role"] == "user":
                    # æ£€æŸ¥æ˜¯å¦æ˜¯åˆå§‹æ¶ˆæ¯ï¼ˆåŒ…å«è¡¨æ ¼çš„æ¶ˆæ¯ï¼‰
                    if DEFAULT_TABLE_CONTENT_PLACEHOLDER in msg['content'] or "news_title | source" in msg['content']:
                        # åˆå§‹æ¶ˆæ¯åªæ˜¾ç¤ºæç¤ºè¯éƒ¨åˆ†ï¼Œä¸æ˜¾ç¤ºè¡¨æ ¼
                        st.markdown(f"ğŸ§‘â€ğŸ’» **You** {DEFAULT_USER_PROMPT}")
                    else:
                        # åç»­æ¶ˆæ¯æ˜¾ç¤ºå®é™…ç”¨æˆ·è¾“å…¥
                        st.markdown(f"ğŸ§‘â€ğŸ’» **You:** {msg['content']}")
                elif msg["role"] == "assistant":
                    st.markdown(f"ğŸ‘¾ **AI:** {msg['content']}")

            # æ£€æŸ¥æ˜¯å¦æœ‰å¾…å¤„ç†çš„ AI å›å¤ï¼ˆå³æœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œä½†æ²¡æœ‰å¯¹åº”çš„ AI å›å¤ï¼‰
            last_user_message_idx = -1
            for i in range(len(messages) - 1, -1, -1):
                if messages[i]["role"] == "user":
                    last_user_message_idx = i
                    break

            last_ai_message_idx = -1
            for i in range(len(messages) - 1, -1, -1):
                if messages[i]["role"] == "assistant":
                    last_ai_message_idx = i
                    break

            print(f"DEBUG: æœ€åç”¨æˆ·æ¶ˆæ¯ç´¢å¼•: {last_user_message_idx}")
            print(f"DEBUG: æœ€åAIæ¶ˆæ¯ç´¢å¼•: {last_ai_message_idx}")
            print(f"DEBUG: æ¶ˆæ¯å†å²å†…å®¹: {messages}")

            # ç»§ç»­å¯¹è¯è¾“å…¥
            user_input = st.chat_input("ç»§ç»­ä¸ AI è®¨è®ºè¿™äº›çƒ­ç‚¹...")
            if user_input:
                st.session_state['ai_messages'].append({"role": "user", "content": user_input})
                # é‡æ–°è¿è¡Œä»¥è§¦å‘AIå›å¤ç”Ÿæˆé€»è¾‘
                st.rerun()

            # å¦‚æœæœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œä¸”æ²¡æœ‰ AI å›å¤ï¼Œæˆ–è€…æœ€åä¸€æ¡ AI å›å¤ä¸ºç©ºï¼Œåˆ™æ­£åœ¨ç”Ÿæˆ
            if last_user_message_idx > last_ai_message_idx or (last_ai_message_idx > -1 and messages[last_ai_message_idx]['content'] == ''):
                # å¦‚æœæœ€åä¸€æ¡ AI å›å¤ä¸ºç©ºï¼Œå…ˆåˆ é™¤å®ƒ
                if last_ai_message_idx > -1 and messages[last_ai_message_idx]['content'] == '':
                    st.session_state['ai_messages'].pop(last_ai_message_idx)
                    print("DEBUG: åˆ é™¤ç©ºçš„ AI å›å¤")
                    # é‡æ–°è·å–æ¶ˆæ¯åˆ—è¡¨å’Œç´¢å¼•
                    messages = st.session_state.get('ai_messages', [])
                    last_ai_message_idx = -1
                
                with st.status("AI æ­£åœ¨åˆ†ææ•°æ®...", expanded=True) as status:
                    try:
                        st.write("ğŸ§  æ­£åœ¨å¤„ç†æ‚¨çš„è¯·æ±‚...")
                        # æ£€æŸ¥ AI å®¢æˆ·ç«¯æ˜¯å¦å­˜åœ¨
                        if not st.session_state['ai_client']:
                            status.update(label="AI åˆ†æå¤±è´¥", state="error", expanded=True)
                            st.error("AI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                            st.toast("âŒ AI åˆ†æå¤±è´¥", icon="âš ï¸")
                        else:
                            st.write("ğŸš€ è°ƒç”¨ AI æ¨¡å‹è¿›è¡Œåˆ†æ...")
                            print("DEBUG: è°ƒç”¨ chat.completions.create()")
                            stream = st.session_state['ai_client'].chat.completions.create(
                                model=ai_model,
                                messages=messages, # åŒ…å«å®Œæ•´å†å²ï¼ˆåŒ…å«è¡¨æ ¼ï¼‰
                                stream=True,
                            )
                            
                            st.write("ğŸ“Š æ­£åœ¨æ¥æ”¶åˆ†æç»“æœ...")
                            print("DEBUG: æˆåŠŸè·å–æµå¼å“åº”")
                            full_response = ""
                            # åˆ›å»ºä¸€ä¸ªå ä½ç¬¦ç”¨äºæµå¼æ˜¾ç¤º AI å›å¤
                            ai_response_placeholder = st.empty()
                            ai_response_placeholder.markdown("ğŸ¤– **AI:** ç”Ÿæˆä¸­...")
                            
                            print("DEBUG: å¼€å§‹æ¥æ”¶æµå¼æ•°æ®")
                            for chunk in stream:
                                print(f"DEBUG: æ¥æ”¶åˆ° chunk: {chunk}")
                                if chunk.choices[0].delta.content is not None:
                                    chunk_content = chunk.choices[0].delta.content
                                    print(f"DEBUG: æ¥æ”¶åˆ°å†…å®¹: '{chunk_content}'")
                                    full_response += chunk_content
                                    print(f"DEBUG: å½“å‰ full_response: '{full_response}'")
                                    # å®æ—¶æ›´æ–°å ä½ç¬¦
                                    ai_response_placeholder.markdown(f"ğŸ¤– **AI:** {full_response}")
                            
                            print(f"DEBUG: æµå¼ç»“æŸï¼Œæœ€ç»ˆ full_response: '{full_response}'")
                            print(f"DEBUG: full_response é•¿åº¦: {len(full_response)}")
                            
                            # å¾ªç¯ç»“æŸåï¼Œä¿å­˜å®Œæ•´çš„ AI å›å¤
                            st.session_state['ai_messages'].append({"role": "assistant", "content": full_response})
                            print(f"DEBUG: ä¼šè¯çŠ¶æ€æ¶ˆæ¯é•¿åº¦: {len(st.session_state['ai_messages'])}")
                            print(f"DEBUG: æœ€åä¸€æ¡æ¶ˆæ¯: {st.session_state['ai_messages'][-1]}")
                            
                            status.update(label="AI åˆ†æå®Œæˆ", state="complete", expanded=False)
                            st.toast("âœ… AI åˆ†æå®Œæˆï¼", icon="ğŸ“Š")
                            # ç§»é™¤å ä½ç¬¦
                            ai_response_placeholder.empty()
                            print("DEBUG: æ˜¾ç¤ºæœ€ç»ˆå›å¤å®Œæˆ")
                            # é‡æ–°è¿è¡Œä»¥åˆ·æ–°ç•Œé¢ï¼Œæ˜¾ç¤ºæ–°æ¶ˆæ¯
                            st.rerun()
                    except Exception as e:
                        print(f"DEBUG: å¼‚å¸¸å‘ç”Ÿ: {e}")
                        status.update(label="AI åˆ†æå¤±è´¥", state="error", expanded=True)
                        st.error(f"AI è°ƒç”¨å¤±è´¥: {e}")
                        st.toast("âŒ AI åˆ†æå¤±è´¥", icon="âš ï¸")
                        # å¯ä»¥é€‰æ‹©ç§»é™¤å¾…å¤„ç†çš„æ¶ˆæ¯ï¼Œæˆ–ä¿ç•™ä»¥ä¾¿é‡è¯•
                        # st.session_state['ai_messages'].pop() # ç§»é™¤æœ€åçš„ç”¨æˆ·æ¶ˆæ¯
            # å¦‚æœæœ‰ AI å›å¤ï¼Œä½†æœªæ˜¾ç¤ºï¼ˆæ¯”å¦‚åˆšä»æµå¼ç»“æŸï¼‰ï¼Œåˆ™æ˜¾ç¤ºå®ƒ
            elif last_ai_message_idx == len(messages) - 1:
                # æœ€åä¸€æ¡æ˜¯ AI æ¶ˆæ¯ï¼Œä½†ä¸Šé¢çš„å¾ªç¯å·²ç»æ˜¾ç¤ºè¿‡äº†ï¼Œæ— éœ€é‡å¤
                # è¿™ä¸ªåˆ†æ”¯ä¸»è¦æ˜¯ä¸ºäº†é€»è¾‘å®Œæ•´æ€§
                pass

else:
    st.info("åœ¨æ‰€é€‰æ—¥æœŸèŒƒå›´å†…æœªæ‰¾åˆ°ä»»ä½•æ•°æ®æˆ–ç›¸å…³æ–‡ä»¶ã€‚")

# å¯é€‰ï¼šæä¾›ä¸€ä¸ªæ‰‹åŠ¨åˆ·æ–°æŒ‰é’®
# if st.button("Refresh Data"):
#     start_date = (datetime.now().date() - timedelta(days=7)) # æˆ–æ ¹æ®å½“å‰é€‰æ‹©çš„èŒƒå›´
#     end_date = datetime.now().date()
#     st.session_state['data'] = load_data_by_date_range(start_date, end_date)
#     st.rerun()